#!/usr/bin/env python3
"""
DMM APIã‹ã‚‰ãƒ‹ãƒƒãƒã‚¸ãƒ£ãƒ³ãƒ«ã®ã‚¢ãƒ€ãƒ«ãƒˆå‹•ç”»ã®äººæ°—ä½œå“ã‚’å–å¾—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è¤‡æ•°ã®ã‚¸ãƒ£ãƒ³ãƒ«ã«å¯¾å¿œ
"""

import os
import json
import sys
import ssl
import argparse
import time
from datetime import datetime
from urllib.parse import urlencode
import urllib.request
from typing import Dict, List, Any, Optional

# ãƒ‹ãƒƒãƒã‚¸ãƒ£ãƒ³ãƒ«ã®å®šç¾©
NICHE_GENRES = {
    "drama": {
        "keyword": "ãƒ‰ãƒ©ãƒ",
        "name": "ãƒ‰ãƒ©ãƒãƒ»ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ç³»",
        "filter_keywords": ["ãƒ‰ãƒ©ãƒ", "ã‚¹ãƒˆãƒ¼ãƒªãƒ¼", "story", "drama"]
    },
    "reverse_ntr": {
        "keyword": "é€†NTR",
        "name": "é€†NTRå°‚é–€",
        "filter_keywords": ["é€†NTR", "é€†å¯å–ã‚‰ã‚Œ", "Mç”·", "å¥³æ€§ä¸Šä½"]
    },
    "danchi": {
        "keyword": "å›£åœ°å¦»",
        "name": "å›£åœ°å¦»ãƒ»äººå¦»ãƒ‰ãƒ©ãƒ",
        "filter_keywords": ["å›£åœ°å¦»", "äººå¦»", "è¿‘æ‰€ã®å¥¥ã•ã‚“"]
    },
    "giri": {
        "keyword": "ç¾©æ¯",
        "name": "ç¾©ç†ã®é–¢ä¿‚å°‚é–€",
        "filter_keywords": ["ç¾©æ¯", "ç¾©å§‰", "ç¾©å¦¹", "ç¾©ç†"]
    },
    "debut": {
        "keyword": "æ–°äºº",
        "name": "æ–°äººAVå¥³å„ªãƒ‡ãƒ“ãƒ¥ãƒ¼ä½œ",
        "filter_keywords": ["æ–°äºº", "ãƒ‡ãƒ“ãƒ¥ãƒ¼", "åˆæ’®ã‚Š", "åˆã‚ã¦"]
    },
    "height": {
        "keyword": "å°æŸ„",
        "name": "èº«é•·å·®ã‚«ãƒƒãƒ—ãƒ«",
        "filter_keywords": ["å°æŸ„", "èº«é•·å·®", "ä½“æ ¼å·®", "150cm"]
    },
    "dialect": {
        "keyword": "é–¢è¥¿å¼",
        "name": "æ–¹è¨€å¥³å­å°‚é–€",
        "filter_keywords": ["é–¢è¥¿å¼", "åšå¤šå¼", "æ–¹è¨€", "å¤§é˜ªå¼"]
    },
    "glasses": {
        "keyword": "çœ¼é¡",
        "name": "çœ¼é¡ã£å­ãƒ»ã‚¤ãƒ³ãƒ†ãƒªç³»",
        "filter_keywords": ["çœ¼é¡", "ã‚¤ãƒ³ãƒ†ãƒª", "æ•™å¸«", "ç§˜æ›¸", "ãƒ¡ã‚¬ãƒ"]
    },
    "location": {
        "keyword": "æ¸©æ³‰",
        "name": "ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ä½œå“",
        "filter_keywords": ["æ¸©æ³‰", "æµ·", "é‡å¤–", "ãƒ“ãƒ¼ãƒ", "ãƒ­ã‚±"]
    },
    "acting": {
        "keyword": "æ¼”æŠ€",
        "name": "æ¼”æŠ€åŠ›é‡è¦–ä½œå“",
        "filter_keywords": ["æ¼”æŠ€", "ãƒ‰ãƒ©ãƒ", "ã‚¹ãƒˆãƒ¼ãƒªãƒ¼", "æ¼”å‡º"]
    }
}


def fetch_dmm_ranking(api_id: str, affiliate_id: str, keyword: str, sort: str = "rank", hits: int = 20, offset: int = 1) -> Dict[str, Any]:
    """
    DMM APIã‹ã‚‰æŒ‡å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã‚¢ãƒ€ãƒ«ãƒˆå‹•ç”»ã®äººæ°—ä½œå“ã‚’å–å¾—
    
    Args:
        api_id: DMM API ID
        affiliate_id: ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆID
        keyword: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        sort: ã‚½ãƒ¼ãƒˆé †ï¼ˆrank, date, priceï¼‰
        hits: å–å¾—ä»¶æ•°
        offset: ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã€1ã‹ã‚‰é–‹å§‹ï¼‰
        
    Returns:
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSON
    """
    base_url = "https://api.dmm.com/affiliate/v3/ItemList"
    
    params = {
        "api_id": api_id,
        "affiliate_id": affiliate_id,
        "site": "FANZA",  # ã‚¢ãƒ€ãƒ«ãƒˆå°‚ç”¨ã‚µã‚¤ãƒˆ
        "service": "digital",  # ãƒ‡ã‚¸ã‚¿ãƒ«å•†å“
        "floor": "videoa",  # ã‚¢ãƒ€ãƒ«ãƒˆå‹•ç”»
        "keyword": keyword,  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
        "sort": sort,  # ã‚½ãƒ¼ãƒˆé †
        "hits": hits,  # å–å¾—ä»¶æ•°
        "offset": offset,  # ã‚ªãƒ•ã‚»ãƒƒãƒˆ
        "output": "json"
    }
    
    url = f"{base_url}?{urlencode(params)}"
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šURLã‚’è¡¨ç¤ºï¼ˆèªè¨¼æƒ…å ±ã¯ãƒã‚¹ã‚¯ï¼‰
    debug_url = url.replace(api_id, "***API_ID***").replace(affiliate_id, "***AFFILIATE_ID***")
    print(f"ğŸ” ãƒªã‚¯ã‚¨ã‚¹ãƒˆURL: {debug_url}")
    
    try:
        # macOSã§SSLè¨¼æ˜æ›¸ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®å¯¾ç­–
        # SSLæ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
        context.check_hostname = False
        context.verify_mode = ssl.CERT_NONE
        
        req = urllib.request.Request(url)
        # contextã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
        with urllib.request.urlopen(req, context=context, timeout=30) as response:
            data = response.read()
            return json.loads(data.decode('utf-8'))
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8') if e.fp else "è©³ç´°æƒ…å ±ãªã—"
        print(f"HTTPã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e.code} {e.reason}", file=sys.stderr)
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_body}", file=sys.stderr)
        sys.exit(1)
    except urllib.error.URLError as e:
        print(f"URLã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e.reason}", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"JSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        sys.exit(1)


def extract_ranking_data(api_response: Dict[str, Any], filter_keywords: Optional[List[str]] = None) -> List[Dict[str, Any]]:
    """
    APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    
    Args:
        api_response: DMM APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        filter_keywords: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        
    Returns:
        æ•´å½¢ã•ã‚ŒãŸãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
    """
    if "result" not in api_response or "items" not in api_response["result"]:
        print("APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒäºˆæœŸã—ãªã„å½¢å¼ã§ã™", file=sys.stderr)
        return []
    
    items = api_response["result"]["items"]
    ranking = []
    
    for idx, item in enumerate(items, start=1):
        ranking_item = {
            "rank": idx,
            "content_id": item.get("content_id", ""),
            "title": item.get("title", ""),
            "url": item.get("URL", ""),
            "affiliate_url": item.get("affiliateURL", ""),
            "image_url": item.get("imageURL", {}).get("large", ""),
            "price": item.get("prices", {}).get("price", ""),
            "release_date": item.get("date", ""),
            "actress": [actress.get("name", "") for actress in item.get("iteminfo", {}).get("actress", [])],
            "genre": [genre.get("name", "") for genre in item.get("iteminfo", {}).get("genre", [])],
            "maker": item.get("iteminfo", {}).get("maker", [{}])[0].get("name", "") if item.get("iteminfo", {}).get("maker") else ""
        }
        ranking.append(ranking_item)
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
    if filter_keywords:
        filtered_ranking = []
        for item in ranking:
            title = item.get("title", "").lower()
            genres = [g.lower() for g in item.get("genre", [])]
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯ã‚¸ãƒ£ãƒ³ãƒ«ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            matches = False
            for keyword in filter_keywords:
                if keyword.lower() in title or any(keyword.lower() in g for g in genres):
                    matches = True
                    break
            
            if matches:
                filtered_ranking.append(item)
        
        ranking = filtered_ranking
    
    return ranking


def get_existing_content_ids(content_dir: str) -> set:
    """
    æ—¢å­˜ã®è¨˜äº‹ã‹ã‚‰content_idã‚’å–å¾—
    
    Args:
        content_dir: contentãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        
    Returns:
        content_idã®ã‚»ãƒƒãƒˆ
    """
    existing_ids = set()
    if not os.path.exists(content_dir):
        return existing_ids
    
    try:
        for filename in os.listdir(content_dir):
            if filename.endswith('.md'):
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰content_idã‚’æŠ½å‡ºï¼ˆä¾‹: 2025-12-14-1start00473.md -> 1start00473ï¼‰
                parts = filename.replace('.md', '').split('-')
                if len(parts) >= 4:
                    content_id = '-'.join(parts[3:])  # æ—¥ä»˜éƒ¨åˆ†ã‚’é™¤ã„ãŸæ®‹ã‚Š
                    existing_ids.add(content_id)
    except Exception as e:
        print(f"âš ï¸  æ—¢å­˜è¨˜äº‹ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
    
    return existing_ids


def save_to_json(data: List[Dict[str, Any]], output_path: str) -> None:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä¿å­˜
    
    Args:
        data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
        output_path: ä¿å­˜å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    output_data = {
        "fetched_at": datetime.now().isoformat(),
        "total_count": len(data),
        "ranking": data
    }
    
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    except IOError as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        sys.exit(1)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
    parser = argparse.ArgumentParser(description="DMM APIã‹ã‚‰ãƒ‹ãƒƒãƒã‚¸ãƒ£ãƒ³ãƒ«ã®å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
    parser.add_argument(
        "--genre",
        type=str,
        choices=list(NICHE_GENRES.keys()) + ["all"],
        default="drama",
        help="å–å¾—ã™ã‚‹ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆallã§å…¨ã‚¸ãƒ£ãƒ³ãƒ«å–å¾—ï¼‰"
    )
    parser.add_argument(
        "--sort",
        type=str,
        choices=["rank", "date", "price"],
        default="rank",
        help="ã‚½ãƒ¼ãƒˆé †ï¼ˆrank: ãƒ©ãƒ³ã‚­ãƒ³ã‚°é †, date: æœ€æ–°é †, price: ä¾¡æ ¼é †ï¼‰"
    )
    parser.add_argument(
        "--hits",
        type=int,
        default=20,
        help="å–å¾—ä»¶æ•°"
    )
    parser.add_argument(
        "--past",
        action="store_true",
        help="éå»ä½œã‚’å–å¾—ï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»¥å¤–ã‹ã‚‰ã‚‚å–å¾—ï¼‰"
    )
    parser.add_argument(
        "--pages",
        type=int,
        default=3,
        help="éå»ä½œå–å¾—æ™‚ã®ãƒšãƒ¼ã‚¸æ•°ï¼ˆ1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šhitsä»¶ï¼‰"
    )
    parser.add_argument(
        "--exclude-existing",
        action="store_true",
        help="æ—¢å­˜ã®è¨˜äº‹ï¼ˆcontent/ãƒ•ã‚©ãƒ«ãƒ€ï¼‰ã¨é‡è¤‡ã™ã‚‹ä½œå“ã‚’é™¤å¤–"
    )
    args = parser.parse_args()
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
    api_id = os.environ.get("DMM_API_ID")
    affiliate_id = os.environ.get("DMM_AFFILIATE_ID")
    
    if not api_id:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° DMM_API_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", file=sys.stderr)
        sys.exit(1)
    
    if not affiliate_id:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° DMM_AFFILIATE_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", file=sys.stderr)
        sys.exit(1)
    
    # å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_dir = os.path.join(os.path.dirname(__file__), "..", "data")
    os.makedirs(output_dir, exist_ok=True)
    
    # å–å¾—ã™ã‚‹ã‚¸ãƒ£ãƒ³ãƒ«ã®ãƒªã‚¹ãƒˆ
    if args.genre == "all":
        genres_to_fetch = list(NICHE_GENRES.keys())
    else:
        genres_to_fetch = [args.genre]
    
    print(f"ğŸ“ API ID: {api_id[:10]}... (ãƒã‚¹ã‚¯æ¸ˆã¿)")
    print(f"ğŸ“ ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆID: {affiliate_id}")
    print(f"ğŸ” ã‚½ãƒ¼ãƒˆé †: {args.sort}")
    print(f"ğŸ“Š å–å¾—ä»¶æ•°: {args.hits}ä»¶/ã‚¸ãƒ£ãƒ³ãƒ«")
    print(f"ğŸ¯ å–å¾—ã‚¸ãƒ£ãƒ³ãƒ«æ•°: {len(genres_to_fetch)}å€‹")
    if args.past:
        print(f"ğŸ“š éå»ä½œå–å¾—ãƒ¢ãƒ¼ãƒ‰: æœ‰åŠ¹ï¼ˆ{args.pages}ãƒšãƒ¼ã‚¸åˆ†ï¼‰")
    if args.exclude_existing:
        print(f"ğŸš« æ—¢å­˜è¨˜äº‹é™¤å¤–: æœ‰åŠ¹")
    print()
    
    # æ—¢å­˜è¨˜äº‹ã®content_idã‚’å–å¾—ï¼ˆé™¤å¤–æ©Ÿèƒ½ãŒæœ‰åŠ¹ãªå ´åˆï¼‰
    existing_content_ids = set()
    if args.exclude_existing:
        content_dir = os.path.join(os.path.dirname(__file__), "..", "content")
        existing_content_ids = get_existing_content_ids(content_dir)
        print(f"ğŸ“‹ æ—¢å­˜è¨˜äº‹æ•°: {len(existing_content_ids)}ä»¶")
        if existing_content_ids:
            print(f"   é™¤å¤–å¯¾è±¡: {', '.join(list(existing_content_ids)[:5])}{'...' if len(existing_content_ids) > 5 else ''}")
        print()
    
    # å„ã‚¸ãƒ£ãƒ³ãƒ«ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿å–å¾—
    all_results = {}
    
    for genre_key in genres_to_fetch:
        genre_info = NICHE_GENRES[genre_key]
        print(f"ğŸ”„ [{genre_info['name']}] ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {genre_info['keyword']}")
        
        try:
            all_items = []
            
            # éå»ä½œå–å¾—ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€è¤‡æ•°ãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—
            if args.past:
                for page in range(1, args.pages + 1):
                    offset = (page - 1) * args.hits + 1
                    print(f"   ğŸ“„ ãƒšãƒ¼ã‚¸ {page} å–å¾—ä¸­ï¼ˆoffset: {offset}ï¼‰...")
                    
                    api_response = fetch_dmm_ranking(
                        api_id, 
                        affiliate_id, 
                        keyword=genre_info['keyword'],
                        sort="date" if args.past else args.sort,  # éå»ä½œå–å¾—æ™‚ã¯æ–°ç€é †
                        hits=args.hits,
                        offset=offset
                    )
                    
                    page_data = extract_ranking_data(api_response, filter_keywords=genre_info['filter_keywords'])
                    all_items.extend(page_data)
                    
                    # æ—¢å­˜è¨˜äº‹ã‚’é™¤å¤–
                    if args.exclude_existing and existing_content_ids:
                        all_items = [item for item in all_items if item.get("content_id") not in existing_content_ids]
                    
                    # ãƒšãƒ¼ã‚¸é–“ã§å°‘ã—å¾…æ©Ÿï¼ˆAPIè² è·è»½æ¸›ï¼‰
                    if page < args.pages:
                        time.sleep(1)
                
                ranking_data = all_items
            else:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆ1ãƒšãƒ¼ã‚¸ã®ã¿ï¼‰
                api_response = fetch_dmm_ranking(
                    api_id, 
                    affiliate_id, 
                    keyword=genre_info['keyword'],
                    sort=args.sort,
                    hits=args.hits
                )
                
                ranking_data = extract_ranking_data(api_response, filter_keywords=genre_info['filter_keywords'])
                
                # æ—¢å­˜è¨˜äº‹ã‚’é™¤å¤–
                if args.exclude_existing and existing_content_ids:
                    ranking_data = [item for item in ranking_data if item.get("content_id") not in existing_content_ids]
            
            # æœ€å¤§ä»¶æ•°ã¾ã§ã«åˆ¶é™
            ranking_data = ranking_data[:args.hits * (args.pages if args.past else 1)]
            
            # ãƒ©ãƒ³ã‚¯ç•ªå·ã‚’1ã‹ã‚‰æŒ¯ã‚Šç›´ã™
            for idx, item in enumerate(ranking_data, start=1):
                item["rank"] = idx
            
            if not ranking_data:
                print(f"   âš ï¸  {genre_info['name']}ã®ä½œå“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                continue
            
            print(f"   âœ… {len(ranking_data)}ä»¶ã®ä½œå“ã‚’å–å¾—ã—ã¾ã—ãŸ")
            
            # ã‚¸ãƒ£ãƒ³ãƒ«ã”ã¨ã«JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            genre_output_path = os.path.join(output_dir, f"dmm_ranking_{genre_key}_{timestamp}.json")
            genre_latest_path = os.path.join(output_dir, f"dmm_ranking_{genre_key}_latest.json")
            
            save_to_json(ranking_data, genre_output_path)
            save_to_json(ranking_data, genre_latest_path)
            
            all_results[genre_key] = {
                "genre_name": genre_info['name'],
                "data": ranking_data
            }
            
            # ç°¡æ˜“è¡¨ç¤º
            print(f"\n   ğŸ“ˆ {genre_info['name']} ãƒ©ãƒ³ã‚­ãƒ³ã‚° TOP5:")
            for item in ranking_data[:5]:
                print(f"      {item['rank']:2d}. {item['title'][:50]}...")
            print()
            
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            continue
    
    # å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã‚’ã¾ã¨ã‚ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if len(genres_to_fetch) > 1:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        combined_path = os.path.join(output_dir, f"dmm_ranking_all_{timestamp}.json")
        combined_latest_path = os.path.join(output_dir, "dmm_ranking_all_latest.json")
        
        combined_data = {
            "fetched_at": datetime.now().isoformat(),
            "genres": all_results
        }
        
        with open(combined_path, "w", encoding="utf-8") as f:
            json.dump(combined_data, f, ensure_ascii=False, indent=2)
        with open(combined_latest_path, "w", encoding="utf-8") as f:
            json.dump(combined_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å…¨ã‚¸ãƒ£ãƒ³ãƒ«çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {combined_latest_path}")
    
    print("\n" + "=" * 80)
    print("ğŸ“Š å–å¾—å®Œäº†ã‚µãƒãƒªãƒ¼:")
    print("=" * 80)
    for genre_key, result in all_results.items():
        print(f"  {result['genre_name']}: {len(result['data'])}ä»¶")
    print("=" * 80)


if __name__ == "__main__":
    main()

