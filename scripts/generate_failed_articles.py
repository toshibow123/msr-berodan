#!/usr/bin/env python3
"""
failed_articles.jsonã‹ã‚‰è¨˜äº‹ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import re
from pathlib import Path
from datetime import datetime
import random

def convert_work_to_info(work: dict, publish_date: str) -> dict:
    """workã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰è¨˜äº‹ç”Ÿæˆç”¨ã®infoè¾æ›¸ã«å¤‰æ›"""
    content_id = work.get("content_id", "")
    title = work.get("title", "")
    actress_list = work.get("actress", [])
    genre_list = work.get("genre", [])
    maker = work.get("maker", "")
    director = work.get("director", "")
    image_url = work.get("image_url", "")
    affiliate_url = work.get("affiliate_url", "")
    release_date = work.get("release_date", "")
    
    # å‡ºæ¼”è€…ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
    actress_str = "ã€".join(actress_list) if actress_list else "ä¸æ˜"
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
    genre_str = "ã€".join(genre_list) if genre_list else "ä¸æ˜"
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLã‚’ç”Ÿæˆï¼ˆcontent_idã‹ã‚‰ï¼‰
    sample_images = []
    for floor in ["videoa", "video"]:
        for i in range(1, 11):  # 1-10æšç›®
            sample_images.append(f"https://pics.dmm.co.jp/digital/{floor}/{content_id}/{content_id}jp-{i}.jpg")
    
    # ç™ºå£²å¹´ã‚’æŠ½å‡º
    year = ""
    if release_date:
        year_match = re.search(r'(\d{4})', release_date)
        if year_match:
            year = year_match.group(1)
    
    # ã‚¿ã‚°ã‚’ç”Ÿæˆ
    tags = []
    if year:
        tags.append(f"{year}å¹´")
    if actress_list:
        tags.extend([actress for actress in actress_list[:2]])
    if genre_list:
        tags.extend([genre for genre in genre_list[:2] if genre not in tags])
    if maker:
        tags.append(maker)
    if len(tags) > 8:
        tags = tags[:8]
    
    return {
        "content_id": content_id,
        "title": title,
        "actress": actress_str,
        "genre": genre_str,
        "maker": maker,
        "director": director,
        "image_url": image_url,
        "affiliate_url": affiliate_url,
        "sample_images": sample_images,
        "tags": tags,
        "rating": round(random.uniform(4.0, 5.0), 1),
        "publish_date": publish_date,
        "year": year
    }


def generate_article_content(info: dict) -> str:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæƒ…å ±ã‹ã‚‰è¨˜äº‹æœ¬æ–‡ã‚’ç”Ÿæˆ"""
    
    # è©©çš„ãªã‚¿ã‚¤ãƒˆãƒ«ã®å€™è£œ
    poetic_titles = [
        "æˆç†Ÿã—ãŸå¥³æ€§ã®é­…åŠ›ãŒç¹”ã‚Šãªã™ã€ç¦æ–­ã®ç‰©èª",
        "å¿ƒã‚’æºã•ã¶ã‚‹ã€å¤§äººã®è‰²æ°—",
        "é™ã‹ã«ã€ã—ã‹ã—æ·±ãå¿ƒã«éŸ¿ã",
        "æˆç†Ÿã—ãŸé­…åŠ›ã«è§¦ã‚Œã‚‹ç¬é–“",
        "ç‰©èªã®å§‹ã¾ã‚Šã«æ„Ÿã˜ãŸã‚‚ã®",
        "å½¼å¥³ã®ä½‡ã¾ã„ã«å¿ƒå¥ªã‚ã‚ŒãŸ",
        "ã“ã®ä½œå“ãŒèªã‚Šã‹ã‘ã‚‹ã‚‚ã®",
        "å¤§äººã®è‰²æ°—ãŒé¦™ã‚Šç«‹ã¤ä¸€æœ¬"
    ]
    
    # ç¬¬ä¸€å°è±¡ã®è¦‹å‡ºã—å€™è£œ
    first_impression_headings = [
        "ä½œå“ã¨ã®å‡ºä¼šã„",
        "å¿ƒã‚’æºã•ã¶ã‚‹ã€ç¦æ–­ã®ç‰©èª",
        "å¤§äººã®è‰²æ°—ãŒé¦™ã‚Šç«‹ã¤ä¸€æœ¬",
        "æˆç†Ÿã—ãŸé­…åŠ›ã«è§¦ã‚Œã‚‹ç¬é–“",
        "é™ã‹ã«ã€ã—ã‹ã—æ·±ãå¿ƒã«éŸ¿ã",
        "ç‰©èªã®å§‹ã¾ã‚Šã«æ„Ÿã˜ãŸã‚‚ã®",
        "å½¼å¥³ã®ä½‡ã¾ã„ã«å¿ƒå¥ªã‚ã‚ŒãŸ",
        "ã“ã®ä½œå“ãŒèªã‚Šã‹ã‘ã‚‹ã‚‚ã®"
    ]
    
    poetic_title = random.choice(poetic_titles)
    first_heading = random.choice(first_impression_headings)
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’é¸æŠï¼ˆæœ€å¤§5æšã€ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼‰
    all_images = info.get('sample_images', [])
    if all_images:
        # ãƒ©ãƒ³ãƒ€ãƒ ã«4-5æšé¸æŠ
        num_images = random.randint(4, 5)
        selected_images = random.sample(all_images, min(num_images, len(all_images)))
    else:
        selected_images = []
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰å…·ä½“çš„ãªè¨­å®šã‚’æŠ½å‡º
    title = info.get('title', '')
    title_keywords = []
    if 'æ¯å­' in title or 'å‹äºº' in title or 'ç¾©' in title:
        title_keywords.append('å®¶æ—é–¢ä¿‚ã®è¤‡é›‘ã•')
    if '5å¹´é–“' in title or 'é•·æœŸé–“' in title or 'å¹´' in title:
        title_keywords.append('é•·ã„æ™‚é–“ã‚’ã‹ã‘ã¦è‚²ã¾ã‚ŒãŸé–¢ä¿‚')
    if 'ã‚»ãƒ•ãƒ¬' in title or 'ä¸å€«' in title or 'å¯å–' in title:
        title_keywords.append('ç¦æ–­ã®é–¢ä¿‚')
    if 'å¹´ä¸‹' in title:
        title_keywords.append('å¹´é½¢å·®ã®ã‚ã‚‹é–¢ä¿‚')
    if 'äººå¦»' in title or 'ä¸»å©¦' in title or 'å¦»' in title:
        title_keywords.append('å®¶åº­ã‚’æŒã¤å¥³æ€§ã®å†…é¢')
    if 'æ¯è¦ª' in title or 'å¦¹' in title or 'å§‰' in title:
        title_keywords.append('å®¶æ—ã¨ã„ã†é–¢ä¿‚æ€§ã®é‡ã•')
    if 'æ•™å¸«' in title or 'å…ˆç”Ÿ' in title:
        title_keywords.append('æ•™è‚²ç¾å ´ã¨ã„ã†ç‰¹åˆ¥ãªç©ºé–“')
    if 'ãƒãƒƒã‚µãƒ¼ã‚¸' in title:
        title_keywords.append('æ–½è¡“ã¨ã„ã†åã®è¦ªå¯†ãªæ™‚é–“')
    if 'ãƒã‚¤ãƒˆ' in title or 'è·å ´' in title or 'åŒåƒš' in title:
        title_keywords.append('æ—¥å¸¸ã®å ´é¢ã‹ã‚‰å§‹ã¾ã‚‹é–¢ä¿‚')
    
    # è¨˜äº‹æœ¬æ–‡ã‚’ç”Ÿæˆ
    content = f"""## {poetic_title}

## {title}

<a href="{info.get('affiliate_url', '')}" target="_blank" rel="sponsored noopener noreferrer">
  <img src="{info.get('image_url', '')}" alt="{title}" />
</a>

**å‡ºæ¼”:** {info.get('actress', 'ä¸æ˜')}
**ã‚¸ãƒ£ãƒ³ãƒ«:** {info.get('genre', '')}
**ãƒ¡ãƒ¼ã‚«ãƒ¼:** {info.get('maker', 'ä¸æ˜')}
{f"**ç›£ç£:** {info.get('director', '')}" if info.get('director') else ''}

<div className="affiliate-link-inline">
  <a href="{info.get('affiliate_url', '')}" target="_blank" rel="noopener noreferrer">ã‚µãƒ³ãƒ—ãƒ«å‹•ç”»ã‚’è¦‹ã‚‹</a>
</div>

<div style="width:100%; padding-top: 75%; position:relative; margin: 2rem 0;"><iframe width="100%" height="100%" max-width="1280px" style="position: absolute; top: 0; left: 0;" src="https://www.dmm.co.jp/litevideo/-/part/=/affi_id=toshichan-002/cid={info.get('content_id', '')}/size=1280_720/" scrolling="no" frameborder="0" allowfullscreen></iframe></div>

## {first_heading}

ã“ã®ä½œå“ã«å‡ºä¼šã£ãŸã®ã¯ã€ã‚ã‚‹é™ã‹ãªå¤œã®ã“ã¨ã ã£ãŸã€‚{info.get('actress', 'å½¼å¥³')}ã¨ã„ã†åå‰ã‚’è¦‹ãŸç¬é–“ã€æˆç†Ÿã—ãŸå¥³æ€§ã®é­…åŠ›ãŒç”»é¢ã‹ã‚‰æº¢ã‚Œå‡ºã¦ãã‚‹ã‚ˆã†ãªäºˆæ„ŸãŒã—ãŸã€‚ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹è¤‡é›‘ãªäººé–“é–¢ä¿‚ã€ç¦æ–­ã®ç‰©èªã®äºˆæ„Ÿã€‚ã“ã‚Œã¯å˜ãªã‚‹ä½œå“ã§ã¯ãªãã€äººé–“ã®æ„Ÿæƒ…ã®æ·±å±¤ã‚’æãå‡ºã™ç‰©èªãªã®ã ã‚ã†ã¨æ„Ÿã˜ãŸã€‚

ç”»é¢ã«æ˜ ã—å‡ºã•ã‚ŒãŸ{info.get('actress', 'å½¼å¥³')}ã®ä½‡ã¾ã„ã¯ã€ã¾ã•ã«æœŸå¾…ã‚’è£åˆ‡ã‚‰ãªã„ã‚‚ã®ã ã£ãŸã€‚æˆç†Ÿã—ãŸå¥³æ€§ç‰¹æœ‰ã®è½ã¡ç€ãã¨ã€ãã‚Œã§ã„ã¦å†…ã«ç§˜ã‚ãŸæƒ…ç†±ãŒã€å½¼å¥³ã®è¡¨æƒ…ã‹ã‚‰æ»²ã¿å‡ºã¦ã„ã‚‹ã€‚æœ€åˆã®ã‚·ãƒ¼ãƒ³ã‹ã‚‰ã€ã“ã®ä½œå“ãŒèªã‚ã†ã¨ã—ã¦ã„ã‚‹ç‰©èªã®é‡ã•ã‚’æ„Ÿã˜å–ã‚‹ã“ã¨ãŒã§ããŸã€‚

## ç‰©èªã®é­…åŠ›

ã“ã®ä½œå“ã¯ã€ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹è¨­å®šãŒã€ç‰©èªã®æ ¸å¿ƒã‚’ãªã—ã¦ã„ã‚‹ã€‚{', '.join(title_keywords) if title_keywords else 'æˆç†Ÿã—ãŸå¥³æ€§ã®å†…é¢'}ã¨ã„ã†ãƒ†ãƒ¼ãƒãŒã€ã©ã®ã‚ˆã†ã«å±•é–‹ã—ã¦ã„ãã®ã‹ã€‚ãã®éç¨‹ã§æã‹ã‚Œã‚‹æ„Ÿæƒ…ã®æ©Ÿå¾®ãŒã€ã“ã®ä½œå“ã®æœ€å¤§ã®é­…åŠ›ã ã€‚

ã‚¿ã‚¤ãƒˆãƒ«ã«è¾¼ã‚ã‚‰ã‚ŒãŸè¨­å®šã¯ã€å˜ãªã‚‹åˆºæ¿€çš„ãªå ´é¢ã‚’è¶…ãˆã¦ã€äººé–“ã®é–¢ä¿‚æ€§ã®è¤‡é›‘ã•ã‚’æãå‡ºã—ã¦ã„ã‚‹ã€‚{info.get('actress', 'å½¼å¥³')}ãŒæ¼”ã˜ã‚‹ç™»å ´äººç‰©ã®å†…é¢ã€ãã®è‘›è—¤ã‚„æƒ…ç†±ãŒã€ä¸å¯§ã«æã‹ã‚Œã¦ã„ãã€‚ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®æ§‹æˆã¯ã€æ™‚é–“ã®æµã‚Œã«æ²¿ã£ã¦ä¸å¯§ã«æã‹ã‚Œã¦ã„ã‚‹ã€‚æ—¥å¸¸çš„ãªå ´é¢ã‹ã‚‰å§‹ã¾ã‚Šã€ãã®å¾Œã®å±•é–‹ã¸ã¨è‡ªç„¶ã«ç§»è¡Œã—ã¦ã„ãã€‚{f"ç›£ç£ã®{info.get('director', '')}ã«ã‚ˆã‚‹" if info.get('director') else ''}æ¼”å‡ºã¯ã€å„ã‚·ãƒ¼ãƒ³ã®æ„å‘³ã‚’ä¸å¯§ã«ç©ã¿é‡ã­ã¦ã„ãæ‰‹æ³•ã§ã€ç‰©èªã®æ·±ã¿ã‚’å¢—ã—ã¦ã„ãã€‚

"""
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’è¿½åŠ ï¼ˆæœ€åˆã®1æšï¼‰
    if selected_images:
        content += f"""<a href="{info.get('affiliate_url', '')}" target="_blank" rel="sponsored noopener noreferrer">
  <img src="{selected_images[0]}" alt="{title}" />
</a>

"""
    
    content += f"""## æ¼”æŠ€ã¨æ¼”å‡ºã®å¦™

{info.get('actress', 'å½¼å¥³')}ã®æ¼”æŠ€ã¯ã€ã“ã®ä½œå“ã®è³ªã‚’æ±ºå®šã¥ã‘ã‚‹é‡è¦ãªè¦ç´ ã ã€‚å½¼å¥³ã®è¡¨æƒ…ã®å¤‰åŒ–ã€ä»•è‰ã®ä¸€ã¤ä¸€ã¤ãŒã€ç™»å ´äººç‰©ã®å†…é¢ã‚’ä¸å¯§ã«è¡¨ç¾ã—ã¦ã„ã‚‹ã€‚ç‰¹ã«å°è±¡çš„ã ã£ãŸã®ã¯ã€è¤‡é›‘ãªæ„Ÿæƒ…ã‚’æŠ±ãˆãªãŒã‚‰ã‚‚ã€ãã‚Œã‚’è¨€è‘‰ã«ã—ãªã„å ´é¢ã§ã®æ¼”æŠ€ã ã€‚è¦–ç·šã®å‹•ãã€å‘¼å¸ã®ãƒªã‚ºãƒ ã€ãã‚Œã‚‰ã™ã¹ã¦ãŒç‰©èªã‚’èªã£ã¦ã„ã‚‹ã€‚

{f"ç›£ç£ã®{info.get('director', '')}ã«ã‚ˆã‚‹" if info.get('director') else ''}æ¼”å‡ºã‚‚ã€ã“ã®ä½œå“ã®è³ªã‚’é«˜ã‚ã¦ã„ã‚‹ã€‚å„ã‚·ãƒ¼ãƒ³ã®æ§‹å›³ã€å…‰ã®ä½¿ã„æ–¹ã€ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã®é¸æŠã€‚ã™ã¹ã¦ãŒç‰©èªã®ãƒ†ãƒ¼ãƒã‚’æ”¯ãˆã‚‹ãŸã‚ã«æ©Ÿèƒ½ã—ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€æ„Ÿæƒ…ã®æ©Ÿå¾®ã‚’è¡¨ç¾ã™ã‚‹å ´é¢ã§ã®æ¼”å‡ºã¯ã€è¦‹ã‚‹è€…ã®å¿ƒã«æ·±ãéŸ¿ãã€‚

ä½œå“ãŒã‚‚ãŸã‚‰ã™ä½™éŸ»ã¯ã€è¦³çµ‚ã‚ã£ãŸå¾Œã‚‚é•·ãå¿ƒã«æ®‹ã‚‹ã€‚å˜ãªã‚‹åˆºæ¿€çš„ãªå ´é¢ã‚’è¶…ãˆã¦ã€äººé–“ã®æ„Ÿæƒ…ã®è¤‡é›‘ã•ã€é–¢ä¿‚æ€§ã®é›£ã—ã•ã‚’æãå‡ºã—ã¦ã„ã‚‹ã€‚ã“ã®ä½œå“ã¯ã€æˆç†Ÿã—ãŸä½œå“ã‚’æ„›ã™ã‚‹è¦–è´è€…ã«ã¨ã£ã¦ã€å¿ƒã«éŸ¿ãä¸€æœ¬ã¨ãªã‚‹ã ã‚ã†ã€‚

"""
    
    # æ®‹ã‚Šã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’è¿½åŠ 
    for img_url in selected_images[1:]:
        content += f"""<a href="{info.get('affiliate_url', '')}" target="_blank" rel="sponsored noopener noreferrer">
  <img src="{img_url}" alt="{title}" />
</a>

"""
    
    content += f"""<div className="affiliate-link-inline">
  <a href="{info.get('affiliate_url', '')}" target="_blank" rel="noopener noreferrer">ã“ã®åä½œã‚’ç¢ºèªã™ã‚‹</a>
</div>

## èª­è€…ã¸ã®èªã‚Šã‹ã‘

ã“ã®ä½œå“ã¯ã€æˆç†Ÿã—ãŸä½œå“ã‚’æ„›ã™ã‚‹æ–¹ã«ãœã²è¦³ã¦ã„ãŸã ããŸã„ä¸€æœ¬ã ã€‚å˜ãªã‚‹åˆºæ¿€ã‚’æ±‚ã‚ã‚‹ã®ã§ã¯ãªãã€ç‰©èªã®æ·±ã¿ã€æ¼”æŠ€ã®å¦™ã€æ¼”å‡ºã®ç¾ã—ã•ã‚’å‘³ã‚ã„ãŸã„æ–¹ã«ã¨ã£ã¦ã€ã“ã®ä½œå“ã¯å¿ƒã«éŸ¿ãä½“é¨“ã‚’æä¾›ã—ã¦ãã‚Œã‚‹ã€‚

{info.get('actress', 'å½¼å¥³')}ã®æ¼”æŠ€ãŒæãå‡ºã™ã€è¤‡é›‘ãªæ„Ÿæƒ…ã®æ©Ÿå¾®ã€‚{f"ç›£ç£ã®{info.get('director', '')}ã«ã‚ˆã‚‹" if info.get('director') else ''}ä¸å¯§ãªæ¼”å‡ºã€‚ãã‚Œã‚‰ãŒç¹”ã‚Šãªã™ç‰©èªã¯ã€è¦³ã‚‹è€…ã®å¿ƒã«é™ã‹ã«ã€ã—ã‹ã—æ·±ãéŸ¿ã„ã¦ã„ãã€‚ã“ã®ä½œå“ãŒã‚‚ãŸã‚‰ã™ä½™éŸ»ã¯ã€è¦³çµ‚ã‚ã£ãŸå¾Œã‚‚é•·ãå¿ƒã«æ®‹ã‚Šç¶šã‘ã‚‹ã ã‚ã†ã€‚

æˆç†Ÿã—ãŸä½œå“ã®é­…åŠ›ã‚’ã€æ´—ç·´ã•ã‚ŒãŸè¨€è‘‰ã§èªã‚‹ã€‚ã“ã®ä½œå“ã¯ã€ã¾ã•ã«ãã®ã‚ˆã†ãªä½œå“ã®ä¸€ã¤ã ã€‚ãœã²ã€ã“ã®ä½œå“ã‚’æ‰‹ã«å–ã£ã¦ã€ãã®é­…åŠ›ã‚’å ªèƒ½ã—ã¦ã„ãŸã ããŸã„ã€‚
"""
    
    return content


def generate_frontmatter(info: dict) -> str:
    """Frontmatterã‚’ç”Ÿæˆ"""
    publish_date = info.get('publish_date', datetime.now().strftime("%Y-%m-%d"))
    
    title = f"{info.get('title', '')} ãƒ¼ åä½œã‚’èªã‚‹"
    excerpt = f"{info.get('title', '')}ã®ç†±ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚åä½œã‚’å†è©•ä¾¡ã™ã‚‹ã€‚"
    tags = info.get('tags', ['2025å¹´'])
    tags_str = ", ".join([f'"{tag}"' for tag in tags])
    
    frontmatter = f"""---
title: "{title}"
date: "{publish_date}"
excerpt: "{excerpt}"
image: "{info.get('image_url', '')}"
tags: [{tags_str}]
affiliateLink: "{info.get('affiliate_url', '')}"
contentId: "{info.get('content_id', '')}"
rating: {info.get('rating', '4.0')}
---

"""
    return frontmatter


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å¤±æ•—è¨˜äº‹ã‹ã‚‰è¨˜äº‹ç”Ÿæˆ")
    parser.add_argument(
        "--overwrite",
        action="store_true",
        help="æ—¢å­˜è¨˜äº‹ã‚’ä¸Šæ›¸ãã™ã‚‹"
    )
    args = parser.parse_args()
    
    print("\n" + "=" * 80)
    print("  å¤±æ•—è¨˜äº‹ã‹ã‚‰è¨˜äº‹ç”Ÿæˆ")
    print("=" * 80 + "\n")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    data_dir = project_root / "data"
    content_dir = project_root / "content"
    
    content_dir.mkdir(exist_ok=True)
    
    # failed_articles.jsonã‚’èª­ã¿è¾¼ã‚€
    failed_file = data_dir / "failed_articles.json"
    if not failed_file.exists():
        print(f"âŒ å¤±æ•—è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {failed_file}", file=sys.stderr)
        sys.exit(1)
    
    with open(failed_file, "r", encoding="utf-8") as f:
        failed_articles = json.load(f)
    
    print(f"ğŸ“– {len(failed_articles)}ä»¶ã®å¤±æ•—è¨˜äº‹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    if args.overwrite:
        print("âš ï¸  æ—¢å­˜è¨˜äº‹ã‚’ä¸Šæ›¸ããƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™\n")
    else:
        print()
    
    # è¨˜äº‹ç”Ÿæˆ
    success_count = 0
    skip_count = 0
    
    for idx, failed_item in enumerate(failed_articles, 1):
        content_id = failed_item.get("content_id", "")
        publish_date = failed_item.get("publish_date", datetime.now().strftime("%Y-%m-%d"))
        work = failed_item.get("work", {})
        
        print(f"[{idx}/{len(failed_articles)}] ğŸ“ {content_id}")
        print(f"   ä½œå“å: {work.get('title', 'ä¸æ˜')[:50]}...")
        
        # workã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰infoè¾æ›¸ã«å¤‰æ›
        info = convert_work_to_info(work, publish_date)
        
        # æ—¢å­˜è¨˜äº‹ã®ãƒã‚§ãƒƒã‚¯
        filename = f"{publish_date}-{content_id}.md"
        existing_file = content_dir / filename
        
        if existing_file.exists() and not args.overwrite:
            print(f"   â­ï¸  æ—¢å­˜è¨˜äº‹ãŒã‚ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            skip_count += 1
            continue
        elif existing_file.exists() and args.overwrite:
            print(f"   âš ï¸  æ—¢å­˜è¨˜äº‹ã‚’ä¸Šæ›¸ãã—ã¾ã™")
        
        # è¨˜äº‹ç”Ÿæˆ
        print(f"   âœï¸  ç”Ÿæˆä¸­...")
        frontmatter = generate_frontmatter(info)
        article_content = generate_article_content(info)
        full_content = frontmatter + article_content
        
        # ä¿å­˜
        filepath = existing_file
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(full_content)
            print(f"   âœ… ä¿å­˜å®Œäº†: {filepath.name}")
            success_count += 1
        except Exception as e:
            print(f"   âŒ ä¿å­˜å¤±æ•—: {e}")
        
        print()
    
    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    print("=" * 80)
    print("ğŸ‰ è¨˜äº‹ç”Ÿæˆå®Œäº†ï¼")
    print("=" * 80)
    print(f"âœ… æˆåŠŸ: {success_count}æœ¬")
    print(f"â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {skip_count}æœ¬")
    print(f"ğŸ“ ä¿å­˜å…ˆ: {content_dir}")
    print("=" * 80)
    print()


if __name__ == "__main__":
    import sys
    main()

