#!/usr/bin/env python3
"""
MGSè¨˜äº‹ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ä¿®æ­£ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é‡è¤‡ã‚’å‰Šé™¤ã—ã€æ­£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLã‚’è¨­å®š
"""

import re
import json
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
script_dir = Path(__file__).parent
project_root = script_dir.parent
content_dir = project_root / "content"

def extract_frontmatter(content: str) -> tuple[dict, str]:
    """ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡º"""
    if not content.startswith("---"):
        return {}, content
    
    end_pos = content.find("\n---", 3)
    if end_pos == -1:
        return {}, content
    
    frontmatter_text = content[4:end_pos].strip()
    body = content[end_pos + 5:].strip()
    
    frontmatter = {}
    for line in frontmatter_text.split("\n"):
        if ":" in line:
            key, value = line.split(":", 1)
            key = key.strip()
            value = value.strip().strip('"')
            frontmatter[key] = value
    
    return frontmatter, body

def generate_mgs_sample_image_urls(image_url: str, content_id: str, count: int = 3) -> list[str]:
    """MGSã®ãƒ¡ã‚¤ãƒ³ç”»åƒURLã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLã‚’ç”Ÿæˆ"""
    if not image_url or "image.mgstage.com" not in image_url:
        return []
    
    match = re.search(r'https://image\.mgstage\.com/images/(.+?)/(.+?)/(.+?)/pf_o2_(.+?)\.jpg', image_url)
    if not match:
        match = re.search(r'https://image\.mgstage\.com/images/(.+?)/(.+?)/(.+?)/pf_(.+?)\.jpg', image_url)
        if not match:
            return []
    
    maker = match.group(1)
    series = match.group(2)
    id_part = match.group(3)
    base_name = match.group(4)
    
    sample_urls = []
    for i in range(1, count + 1):
        sample_url = f"https://image.mgstage.com/images/{maker}/{series}/{id_part}/pf_{base_name}-{i}.jpg"
        sample_urls.append(sample_url)
    
    return sample_urls

def fix_sample_images_in_body(body: str, image_url: str, content_id: str, affiliate_url: str, title: str) -> str:
    """æœ¬æ–‡å†…ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä¿®æ­£ï¼ˆé‡è¤‡ã‚’å‰Šé™¤ï¼‰"""
    sample_urls = generate_mgs_sample_image_urls(image_url, content_id, count=3)
    
    if not sample_urls:
        sample_urls = [image_url] * 3
    
    # ã€Œå¿ƒã«æ®‹ã‚‹ã‚·ãƒ¼ãƒ³ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
    scene_section_match = re.search(r'## å¿ƒã«æ®‹ã‚‹ã‚·ãƒ¼ãƒ³', body)
    
    if scene_section_match:
        section_start = scene_section_match.start()
        before_section = body[:section_start]
        after_section = body[section_start:]
        
        # ã€Œèª­è€…ã¸ã®èªã‚Šã‹ã‘ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        next_section_match = re.search(r'\n## èª­è€…ã¸ã®èªã‚Šã‹ã‘', after_section)
        if next_section_match:
            section_end = section_start + next_section_match.start()
            rest_body = body[section_end:]
        else:
            section_end = len(body)
            rest_body = ""
        
        # ã€Œå¿ƒã«æ®‹ã‚‹ã‚·ãƒ¼ãƒ³ã€ã‹ã‚‰ã€Œèª­è€…ã¸ã®èªã‚Šã‹ã‘ã€ã¾ã§ã®éƒ¨åˆ†ã‚’å–å¾—
        section_body = body[section_start:section_end]
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã®å…¨ã¦ã®ç”»åƒã‚¿ã‚°ã‚’å‰Šé™¤ï¼ˆè¤‡æ•°è¡Œå¯¾å¿œï¼‰
        img_pattern = r'<a href="[^"]*" target="_blank" rel="sponsored noopener noreferrer">\s*<img src="[^"]*"[^>]*/>\s*</a>\s*\n?'
        section_body = re.sub(img_pattern, '', section_body, flags=re.MULTILINE)
        
        # ã€Œã“ã®åä½œã‚’ç¢ºèªã™ã‚‹ã€ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        link_pattern = r'<div className="affiliate-link-inline">[^<]*</div>'
        link_match = re.search(link_pattern, section_body)
        
        # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ç”Ÿæˆ
        images_html = "\n\n"
        for sample_url in sample_urls:
            images_html += f'<a href="{affiliate_url}" target="_blank" rel="sponsored noopener noreferrer">\n  <img src="{sample_url}" alt="{title}" />\n</a>\n\n'
        
        if link_match:
            # ãƒªãƒ³ã‚¯ã®å‰ã«ç”»åƒã‚’æŒ¿å…¥
            insert_pos = link_match.start()
            section_body = section_body[:insert_pos] + images_html + section_body[insert_pos:]
        else:
            # ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æœ€å¾Œã«è¿½åŠ 
            section_body = section_body.rstrip() + images_html
        
        # ã€Œèª­è€…ã¸ã®èªã‚Šã‹ã‘ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä»¥é™ã®ç”»åƒã‚‚å‰Šé™¤
        if rest_body:
            rest_body = re.sub(img_pattern, '', rest_body, flags=re.MULTILINE)
        
        body = before_section + section_body + rest_body
    
    return body

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("  MGSè¨˜äº‹ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒä¿®æ­£ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼‰")
    print("=" * 80 + "\n")
    
    mgs_articles = list(content_dir.glob("2026-01-02-*.md"))
    
    if not mgs_articles:
        print("âŒ ä¿®æ­£å¯¾è±¡ã®è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ“‹ {len(mgs_articles)}ä»¶ã®è¨˜äº‹ã‚’ä¿®æ­£ã—ã¾ã™\n")
    
    fixed_count = 0
    skipped_count = 0
    
    for article_file in mgs_articles:
        try:
            with open(article_file, "r", encoding="utf-8") as f:
                content = f.read()
            
            frontmatter, body = extract_frontmatter(content)
            
            if not frontmatter:
                print(f"â­ï¸  {article_file.name} - ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                skipped_count += 1
                continue
            
            source = frontmatter.get("source", "")
            if source != "MGS":
                print(f"â­ï¸  {article_file.name} - MGSè¨˜äº‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                skipped_count += 1
                continue
            
            image_url = frontmatter.get("image", "")
            content_id = frontmatter.get("contentId", "")
            affiliate_url = frontmatter.get("affiliateLink", "")
            title = frontmatter.get("title", "")
            
            if not image_url or not content_id:
                print(f"â­ï¸  {article_file.name} - å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                skipped_count += 1
                continue
            
            new_body = fix_sample_images_in_body(body, image_url, content_id, affiliate_url, title)
            
            frontmatter_lines = ["---"]
            for key, value in frontmatter.items():
                if isinstance(value, str):
                    frontmatter_lines.append(f'{key}: "{value}"')
                else:
                    frontmatter_lines.append(f'{key}: {json.dumps(value, ensure_ascii=False)}')
            frontmatter_lines.append("---")
            
            new_content = "\n".join(frontmatter_lines) + "\n\n" + new_body
            
            with open(article_file, "w", encoding="utf-8") as f:
                f.write(new_content)
            
            print(f"âœ… {article_file.name} - ä¿®æ­£å®Œäº†")
            fixed_count += 1
                
        except Exception as e:
            print(f"âŒ {article_file.name} - ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 80)
    print(f"ğŸ‰ ä¿®æ­£å®Œäº†ï¼")
    print(f"   ä¿®æ­£: {fixed_count}ä»¶")
    print(f"   ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶")
    print("=" * 80)

if __name__ == "__main__":
    main()

