#!/usr/bin/env python3
"""
DMM APIã‹ã‚‰ç†Ÿå¥³ãƒ»äººå¦»ãƒ»ãƒ‰ãƒ©ãƒä½œå“ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®˜èƒ½å°èª¬ã‚µã‚¤ãƒˆã€Œè‰¶ã‚ãç‰©èªã€å°‚ç”¨
"""

import os
import json
import sys
import ssl
import argparse
import time
from datetime import datetime
from urllib.parse import urlencode
import urllib.request
import urllib.error
from typing import Dict, List, Any
from pathlib import Path

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
try:
    from dotenv import load_dotenv
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    env_path = project_root / ".env"
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {env_path}")
    else:
        print(f"âš ï¸  .envãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {env_path}")
except ImportError:
    print("âš ï¸  python-dotenvãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install python-dotenv ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
except Exception as e:
    print(f"âš ï¸  .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# ç†Ÿå¥³ãƒ»äººå¦»ãƒ»ãƒ‰ãƒ©ãƒã‚¸ãƒ£ãƒ³ãƒ«ã®å®šç¾©
MATURE_DRAMA_GENRES = {
    "mature": {
        "keyword": "ç†Ÿå¥³",
        "name": "ç†Ÿå¥³",
        "filter_keywords": ["ç†Ÿå¥³", "ä¸‰åè·¯", "å››åè·¯", "äº”åè·¯", "é‚„æš¦", "ãŠã°ã•ã‚“"]
    },
    "married": {
        "keyword": "äººå¦»",
        "name": "äººå¦»",
        "filter_keywords": ["äººå¦»", "ä¸»å©¦", "å¥¥ã•ã‚“", "å¦»", "å¯å–ã‚‰ã‚Œ", "ãƒãƒˆãƒ©ãƒ¬", "NTR"]
    },
    "drama": {
        "keyword": "ãƒ‰ãƒ©ãƒ",
        "name": "ãƒ‰ãƒ©ãƒ",
        "filter_keywords": ["ãƒ‰ãƒ©ãƒ", "ã‚¹ãƒˆãƒ¼ãƒªãƒ¼", "è¿‘è¦ªç›¸å§¦", "ä¸å€«", "NTR", "ãƒãƒˆãƒ©ãƒ¬", "å¯å–", "å¯å–ã‚‰ã‚Œ"]
    },
}


def fetch_dmm_ranking(
    api_id: str, 
    affiliate_id: str, 
    keyword: str = None,
    sort: str = "rank", 
    hits: int = 50, 
    offset: int = 1,
    genre_id: str = None,
    maker_id: str = None,
    actress_id: str = None,
    series_id: str = None,
    price_from: int = None,
    price_to: int = None,
    gte_date: str = None,
    lte_date: str = None
) -> Dict[str, Any]:
    """
    DMM APIã‹ã‚‰ä½œå“ã‚’å–å¾—
    
    Args:
        api_id: DMM API ID
        affiliate_id: ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆID
        keyword: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        sort: ã‚½ãƒ¼ãƒˆé †ï¼ˆrank, date, price, reviewï¼‰
        hits: å–å¾—ä»¶æ•°
        offset: ã‚ªãƒ•ã‚»ãƒƒãƒˆ
        genre_id: ã‚¸ãƒ£ãƒ³ãƒ«IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        maker_id: ãƒ¡ãƒ¼ã‚«ãƒ¼IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        actress_id: å‡ºæ¼”è€…IDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        series_id: ã‚·ãƒªãƒ¼ã‚ºIDï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        price_from: ä¾¡æ ¼ã®æœ€å°å€¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        price_to: ä¾¡æ ¼ã®æœ€å¤§å€¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        gte_date: ç™ºå£²æ—¥ã®é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        lte_date: ç™ºå£²æ—¥ã®çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
    Returns:
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSON
    """
    base_url = "https://api.dmm.com/affiliate/v3/ItemList"
    
    params = {
        "api_id": api_id,
        "affiliate_id": affiliate_id,
        "site": "FANZA",
        "service": "digital",
        "floor": "videoa",
        "sort": sort,
        "hits": hits,
        "offset": offset,
        "output": "json"
    }
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    if keyword:
        params["keyword"] = keyword
    if genre_id:
        params["genre_id"] = genre_id
    if maker_id:
        params["maker_id"] = maker_id
    if actress_id:
        params["actress_id"] = actress_id
    if series_id:
        params["series_id"] = series_id
    if price_from is not None:
        params["price_from"] = price_from
    if price_to is not None:
        params["price_to"] = price_to
    # DMM APIã®æ—¥ä»˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ä¸€æ—¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
    # ä»£ã‚ã‚Šã«ã€sort=dateã§offsetã‚’å¤§ããã—ã¦éå»ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã™ã‚‹æ–¹æ³•ã‚’ä½¿ç”¨
    # if gte_date:
    #     params["gte_date"] = gte_date
    # if lte_date:
    #     params["lte_date"] = lte_date
    
    url = f"{base_url}?{urlencode(params)}"
    
    try:
        context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
        context.check_hostname = False
        context.verify_mode = ssl.CERT_NONE
        
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req, context=context, timeout=30) as response:
            data = response.read()
            return json.loads(data.decode('utf-8'))
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8') if e.fp else "ã‚¨ãƒ©ãƒ¼è©³ç´°ãªã—"
        print(f"âŒ APIå–å¾—ã‚¨ãƒ©ãƒ¼ (HTTP {e.code}): {e.reason}", file=sys.stderr)
        print(f"   ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_body[:200]}", file=sys.stderr)
        # ãƒ‡ãƒãƒƒã‚°ç”¨: URLã‚’è¡¨ç¤ºï¼ˆèªè¨¼æƒ…å ±ã¯ãƒã‚¹ã‚¯ï¼‰
        debug_url = url.replace(api_id, "***API_ID***").replace(affiliate_id, "***AFFILIATE_ID***")
        print(f"   ãƒªã‚¯ã‚¨ã‚¹ãƒˆURL: {debug_url[:200]}...", file=sys.stderr)
        return {}
    except Exception as e:
        print(f"âŒ APIå–å¾—ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        return {}


def extract_ranking_data(api_response: Dict[str, Any], filter_keywords: List[str] = None) -> List[Dict[str, Any]]:
    """APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    if "result" not in api_response or "items" not in api_response["result"]:
        return []
    
    items = api_response["result"]["items"]
    ranking = []
    
    for idx, item in enumerate(items, start=1):
        ranking_item = {
            "rank": idx,
            "content_id": item.get("content_id", ""),
            "title": item.get("title", ""),
            "url": item.get("URL", ""),
            "affiliate_url": item.get("affiliateURL", ""),
            "image_url": item.get("imageURL", {}).get("large", ""),
            "price": item.get("prices", {}).get("price", ""),
            "release_date": item.get("date", ""),
            "actress": [actress.get("name", "") for actress in item.get("iteminfo", {}).get("actress", [])],
            "genre": [genre.get("name", "") for genre in item.get("iteminfo", {}).get("genre", [])],
            "maker": item.get("iteminfo", {}).get("maker", [{}])[0].get("name", "") if item.get("iteminfo", {}).get("maker") else "",
            "director": item.get("iteminfo", {}).get("director", [{}])[0].get("name", "") if item.get("iteminfo", {}).get("director") else "",
            "description": item.get("review", {}).get("text", "") if item.get("review") else "",
        }
        ranking.append(ranking_item)
    
    # ã‚¸ãƒ£ãƒ³ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆç·©å’Œ: ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯ã‚¸ãƒ£ãƒ³ãƒ«ã«å«ã¾ã‚Œã¦ã„ã‚Œã°OKï¼‰
    if filter_keywords:
        filtered_ranking = []
        for item in ranking:
            title = item.get("title", "").lower()
            genres = [g.lower() for g in item.get("genre", [])]
            genres_str = " ".join(genres)
            
            matches = False
            for keyword in filter_keywords:
                keyword_lower = keyword.lower()
                # ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯ã‚¸ãƒ£ãƒ³ãƒ«ã«å«ã¾ã‚Œã¦ã„ã‚Œã°OK
                if keyword_lower in title or keyword_lower in genres_str:
                    matches = True
                    break
            
            if matches:
                filtered_ranking.append(item)
        
        ranking = filtered_ranking
    
    return ranking


def get_existing_content_ids(content_dir: Path) -> set:
    """æ—¢å­˜ã®è¨˜äº‹ã‹ã‚‰content_idã‚’å–å¾—"""
    existing_ids = set()
    if not content_dir.exists():
        return existing_ids
    
    try:
        for filename in os.listdir(content_dir):
            if filename.endswith('.md'):
                parts = filename.replace('.md', '').split('-')
                if len(parts) >= 4:
                    content_id = '-'.join(parts[3:])
                    existing_ids.add(content_id)
    except Exception as e:
        print(f"âš ï¸  æ—¢å­˜è¨˜äº‹ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
    
    return existing_ids


def is_valid_mature_drama_work(item: Dict[str, Any], debug: bool = False) -> bool:
    """ç†Ÿå¥³ãƒ»äººå¦»ãƒ»ãƒ‰ãƒ©ãƒã«è©²å½“ã™ã‚‹ã‹ã‚’åˆ¤å®š"""
    genres = [g.lower() for g in item.get("genre", [])]
    title = item.get("title", "").lower()
    
    # å¿…é ˆã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆæ‹¡å¼µç‰ˆï¼‰
    valid_keywords = [
        "ç†Ÿå¥³", "äººå¦»", "ä¸»å©¦", "ãƒ‰ãƒ©ãƒ", "ä¸‰åè·¯", "å››åè·¯", "äº”åè·¯",
        "ä¸å€«", "ntr", "ãƒãƒˆãƒ©ãƒ¬", "å¯å–", "å¯å–ã‚‰ã‚Œ", "è¿‘è¦ªç›¸å§¦", "ç¾©æ¯", "ç¾©å§‰", "å¥¥ã•ã‚“",
        "å¦»", "ä¸è²", "äººå¦»ãƒ»ä¸»å©¦", "ç†Ÿå¥³ãƒ»ãŠã°ã•ã‚“", "ãƒ‰ãƒ©ãƒ", "ã‚¹ãƒˆãƒ¼ãƒªãƒ¼"
    ]
    
    # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè‹¥ã„å¥³å„ªã®ã¿ã®ä¼ç”»ã‚‚ã®ï¼‰
    exclude_keywords = [
        "ç´ äºº", "ãƒŠãƒ³ãƒ‘", "ãƒã‚¸ãƒƒã‚¯ãƒŸãƒ©ãƒ¼", "mmå·", "10ä»£", "ã‚®ãƒ£ãƒ«", "jk", "jc"
    ]
    
    # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
    for keyword in exclude_keywords:
        if keyword in title or any(keyword in g for g in genres):
            if debug:
                print(f"      âŒ é™¤å¤–: {keyword} ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            return False
    
    # å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
    for keyword in valid_keywords:
        if keyword in title or any(keyword in g for g in genres):
            if debug:
                print(f"      âœ… è©²å½“: {keyword} ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            return True
    
    if debug:
        print(f"      âš ï¸  è©²å½“ãªã—: ã‚¿ã‚¤ãƒˆãƒ«={title[:50]}, ã‚¸ãƒ£ãƒ³ãƒ«={genres}")
    return False


def save_to_json(data: List[Dict[str, Any]], output_path: str) -> None:
    """ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä¿å­˜"""
    output_data = {
        "fetched_at": datetime.now().isoformat(),
        "total_count": len(data),
        "ranking": data
    }
    
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    except IOError as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", file=sys.stderr)
        sys.exit(1)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="ç†Ÿå¥³ãƒ»äººå¦»ãƒ»ãƒ‰ãƒ©ãƒä½œå“ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—")
    parser.add_argument(
        "--genre",
        type=str,
        choices=list(MATURE_DRAMA_GENRES.keys()) + ["all"],
        default="all",
        help="å–å¾—ã™ã‚‹ã‚¸ãƒ£ãƒ³ãƒ«ï¼ˆallã§å…¨ã‚¸ãƒ£ãƒ³ãƒ«å–å¾—ï¼‰"
    )
    parser.add_argument(
        "--sort",
        type=str,
        choices=["rank", "date", "price"],
        default="rank",
        help="ã‚½ãƒ¼ãƒˆé †"
    )
    parser.add_argument(
        "--hits",
        type=int,
        default=50,
        help="å–å¾—ä»¶æ•°"
    )
    parser.add_argument(
        "--exclude-existing",
        action="store_true",
        help="æ—¢å­˜ã®è¨˜äº‹ã¨é‡è¤‡ã™ã‚‹ä½œå“ã‚’é™¤å¤–"
    )
    parser.add_argument(
        "--mode",
        type=str,
        choices=["ranking", "latest", "all"],
        default="ranking",
        help="å–å¾—ãƒ¢ãƒ¼ãƒ‰: ranking=ãƒ©ãƒ³ã‚­ãƒ³ã‚°é †, latest=æ–°ç€é †, all=ä¸¡æ–¹"
    )
    parser.add_argument(
        "--pages",
        type=int,
        default=1,
        help="å–å¾—ãƒšãƒ¼ã‚¸æ•°ï¼ˆ1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šhitsä»¶ï¼‰"
    )
    parser.add_argument(
        "--genre-id",
        type=str,
        help="ã‚¸ãƒ£ãƒ³ãƒ«IDã§æŒ‡å®šï¼ˆä¾‹: 4001ï¼‰"
    )
    parser.add_argument(
        "--maker-id",
        type=str,
        help="ãƒ¡ãƒ¼ã‚«ãƒ¼IDã§æŒ‡å®š"
    )
    parser.add_argument(
        "--actress-id",
        type=str,
        help="å‡ºæ¼”è€…IDã§æŒ‡å®š"
    )
    parser.add_argument(
        "--series-id",
        type=str,
        help="ã‚·ãƒªãƒ¼ã‚ºIDã§æŒ‡å®š"
    )
    parser.add_argument(
        "--price-from",
        type=int,
        help="ä¾¡æ ¼ã®æœ€å°å€¤ï¼ˆå††ï¼‰"
    )
    parser.add_argument(
        "--price-to",
        type=int,
        help="ä¾¡æ ¼ã®æœ€å¤§å€¤ï¼ˆå††ï¼‰"
    )
    parser.add_argument(
        "--date-from",
        type=str,
        help="ç™ºå£²æ—¥ã®é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰"
    )
    parser.add_argument(
        "--date-to",
        type=str,
        help="ç™ºå£²æ—¥ã®çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰"
    )
    parser.add_argument(
        "--sort-by",
        type=str,
        choices=["rank", "date", "price", "review"],
        default=None,
        help="ã‚½ãƒ¼ãƒˆé †ã‚’ä¸Šæ›¸ãï¼ˆrank=ãƒ©ãƒ³ã‚­ãƒ³ã‚°, date=æ–°ç€, price=ä¾¡æ ¼, review=ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰"
    )
    parser.add_argument(
        "--year-from",
        type=int,
        help="å–å¾—é–‹å§‹å¹´ï¼ˆä¾‹: 2014ï¼‰"
    )
    parser.add_argument(
        "--year-to",
        type=int,
        help="å–å¾—çµ‚äº†å¹´ï¼ˆä¾‹: 2020ï¼‰"
    )
    parser.add_argument(
        "--oldest-first",
        action="store_true",
        help="å¤ã„é †ã«å–å¾—ï¼ˆsort=dateã§offsetã‚’å¤§ããã—ã¦å–å¾—ï¼‰"
    )
    args = parser.parse_args()
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
    api_id = os.environ.get("DMM_API_ID")
    affiliate_id = os.environ.get("DMM_AFFILIATE_ID")
    
    if not api_id or not affiliate_id:
        print("âŒ ç’°å¢ƒå¤‰æ•° DMM_API_ID ã¾ãŸã¯ DMM_AFFILIATE_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", file=sys.stderr)
        sys.exit(1)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    output_dir = project_root / "data"
    content_dir = project_root / "content"
    
    output_dir.mkdir(exist_ok=True)
    
    print("\n" + "âœ¨" * 40)
    print("  ç†Ÿå¥³ãƒ»äººå¦»ãƒ»ãƒ‰ãƒ©ãƒä½œå“ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—")
    print("  ã€œè‰¶ã‚ãç‰©èªã€œ")
    print("âœ¨" * 40 + "\n")
    
    # ã‚½ãƒ¼ãƒˆé †ã®æ±ºå®š
    sort_order = args.sort_by if args.sort_by else args.sort
    print(f"ğŸ” ã‚½ãƒ¼ãƒˆé †: {sort_order}")
    print(f"ğŸ“Š å–å¾—ä»¶æ•°: {args.hits}ä»¶/ã‚¸ãƒ£ãƒ³ãƒ«")
    print(f"ğŸ“„ å–å¾—ãƒ¢ãƒ¼ãƒ‰: {args.mode}")
    if args.pages > 1:
        print(f"ğŸ“„ å–å¾—ãƒšãƒ¼ã‚¸æ•°: {args.pages}ãƒšãƒ¼ã‚¸ï¼ˆåˆè¨ˆæœ€å¤§{args.hits * args.pages}ä»¶/ã‚¸ãƒ£ãƒ³ãƒ«ï¼‰")
    
    # ç™ºå£²æ—¥ç¯„å›²ã®è¨­å®š
    date_from = args.date_from
    date_to = args.date_to
    
    if args.year_from:
        if not date_from:
            date_from = f"{args.year_from}-01-01"
        print(f"ğŸ“… å–å¾—é–‹å§‹å¹´: {args.year_from}å¹´")
    if args.year_to:
        if not date_to:
            date_to = f"{args.year_to}-12-31"
        print(f"ğŸ“… å–å¾—çµ‚äº†å¹´: {args.year_to}å¹´")
    
    if args.oldest_first:
        print(f"â®ï¸  å¤ã„é †å–å¾—ãƒ¢ãƒ¼ãƒ‰: æœ‰åŠ¹ï¼ˆsort=dateã§offsetã‚’å¤§ããã—ã¦å–å¾—ï¼‰")
    
    # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã®è¡¨ç¤º
    if args.genre_id:
        print(f"ğŸ­ ã‚¸ãƒ£ãƒ³ãƒ«IDæŒ‡å®š: {args.genre_id}")
    if args.maker_id:
        print(f"ğŸ­ ãƒ¡ãƒ¼ã‚«ãƒ¼IDæŒ‡å®š: {args.maker_id}")
    if args.actress_id:
        print(f"ğŸ‘¤ å‡ºæ¼”è€…IDæŒ‡å®š: {args.actress_id}")
    if args.series_id:
        print(f"ğŸ“š ã‚·ãƒªãƒ¼ã‚ºIDæŒ‡å®š: {args.series_id}")
    if args.price_from or args.price_to:
        print(f"ğŸ’° ä¾¡æ ¼ç¯„å›²: {args.price_from or 0}å†† ã€œ {args.price_to or 'ä¸Šé™ãªã—'}å††")
    if date_from or date_to:
        print(f"ğŸ“… ç™ºå£²æ—¥ç¯„å›²: {date_from or 'é–‹å§‹ãªã—'} ã€œ {date_to or 'çµ‚äº†ãªã—'}")
    
    # æ—¢å­˜è¨˜äº‹ã®é™¤å¤–è¨­å®š
    existing_content_ids = set()
    if args.exclude_existing:
        existing_content_ids = get_existing_content_ids(content_dir)
        print(f"ğŸš« æ—¢å­˜è¨˜äº‹é™¤å¤–: æœ‰åŠ¹ï¼ˆ{len(existing_content_ids)}ä»¶ï¼‰")
    
    print()
    
    # å–å¾—ã™ã‚‹ã‚¸ãƒ£ãƒ³ãƒ«ã®ãƒªã‚¹ãƒˆ
    if args.genre == "all":
        genres_to_fetch = list(MATURE_DRAMA_GENRES.keys())
    else:
        genres_to_fetch = [args.genre]
    
    all_results = {}
    
    # å„ã‚¸ãƒ£ãƒ³ãƒ«ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿å–å¾—
    for genre_key in genres_to_fetch:
        genre_info = MATURE_DRAMA_GENRES[genre_key]
        print(f"ğŸ”„ [{genre_info['name']}] ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        
        try:
            all_items = []
            
            # å–å¾—ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦è¤‡æ•°ãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—
            if args.mode == "ranking":
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°é †ã®ã¿
                sort_mode = "rank"
                pages_to_fetch = args.pages
            elif args.mode == "latest":
                # æ–°ç€é †ã®ã¿
                sort_mode = "date"
                pages_to_fetch = args.pages
            else:  # all
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°é †ã¨æ–°ç€é †ã®ä¸¡æ–¹
                sort_mode = "rank"
                pages_to_fetch = args.pages
            
            # å¤ã„é †å–å¾—ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€offsetã‚’å¤§ããã—ã¦éå»ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—
            if args.oldest_first:
                sort_mode = "date"
                # å¤ã„é †ã«å–å¾—ã™ã‚‹ãŸã‚ã€offsetã‚’å¤§ããè¨­å®š
                # ä¾‹: 1000ä»¶ç›®ã‹ã‚‰å–å¾—ã™ã‚‹å ´åˆã€offset=1001
                base_offset = 1000  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®é–‹å§‹offset
                pages_to_fetch = args.pages
            
            # ç™ºå£²æ—¥ç¯„å›²æŒ‡å®šãŒã‚ã‚‹å ´åˆã€sort=dateã§offsetã‚’èª¿æ•´ã—ã¦å–å¾—
            # DMM APIã§ã¯ç›´æ¥æ—¥ä»˜ç¯„å›²ã‚’æŒ‡å®šã§ããªã„ãŸã‚ã€sort=dateã§å¤§é‡ã®offsetã‹ã‚‰å–å¾—
            if date_from or date_to:
                sort_mode = "date"
                # æ—¥ä»˜ç¯„å›²æŒ‡å®šæ™‚ã¯ã€offsetã‚’å¤§ããã—ã¦éå»ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—
                # 2014å¹´ã‹ã‚‰å–å¾—ã™ã‚‹å ´åˆã€offsetã‚’å¤§ããè¨­å®š
                if date_from:
                    # 2014å¹´ã‹ã‚‰å–å¾—ã™ã‚‹å ´åˆã€offsetã‚’5000ç¨‹åº¦ã«è¨­å®š
                    try:
                        year = int(date_from.split("-")[0])
                        if year <= 2015:
                            base_offset = 5000  # 2015å¹´ä»¥å‰ã¯offsetã‚’å¤§ãã
                        elif year <= 2018:
                            base_offset = 3000
                        elif year <= 2020:
                            base_offset = 1000
                        else:
                            base_offset = 0
                    except:
                        base_offset = 1000
                else:
                    base_offset = 0
            
            # è¤‡æ•°ãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—
            for page in range(1, pages_to_fetch + 1):
                if args.oldest_first or (date_from or date_to):
                    # å¤ã„é †ã¾ãŸã¯æ—¥ä»˜ç¯„å›²æŒ‡å®š: offsetã‚’å¤§ããã—ã¦éå»ã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—
                    offset = base_offset + (page - 1) * args.hits + 1
                else:
                    offset = (page - 1) * args.hits + 1
                
                if pages_to_fetch > 1:
                    print(f"   ğŸ“„ ãƒšãƒ¼ã‚¸ {page}/{pages_to_fetch} å–å¾—ä¸­ï¼ˆoffset: {offset}ï¼‰...")
                
                api_response = fetch_dmm_ranking(
                    api_id,
                    affiliate_id,
                    keyword=genre_info['keyword'] if not args.genre_id else None,
                    sort=sort_order,
                    hits=args.hits,
                    offset=offset,
                    genre_id=args.genre_id,
                    maker_id=args.maker_id,
                    actress_id=args.actress_id,
                    series_id=args.series_id,
                    price_from=args.price_from,
                    price_to=args.price_to,
                    gte_date=None,  # DMM APIã§ã¯ç›´æ¥æ—¥ä»˜ç¯„å›²æŒ‡å®šãŒã§ããªã„ãŸã‚ã€Noneã«è¨­å®š
                    lte_date=None   # sort=dateã§offsetã‚’èª¿æ•´ã—ã¦å–å¾—
                )
                
                page_data = extract_ranking_data(api_response, filter_keywords=genre_info['filter_keywords'])
                all_items.extend(page_data)
                
                # ãƒšãƒ¼ã‚¸é–“ã§å°‘ã—å¾…æ©Ÿï¼ˆAPIè² è·è»½æ¸›ï¼‰
                if page < pages_to_fetch:
                    time.sleep(1)
            
            # allãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€æ–°ç€é †ã‚‚å–å¾—
            if args.mode == "all":
                print(f"   ğŸ“„ æ–°ç€é †ã‚‚å–å¾—ä¸­...")
                for page in range(1, args.pages + 1):
                    offset = (page - 1) * args.hits + 1
                    if args.pages > 1:
                        print(f"   ğŸ“„ æ–°ç€é † ãƒšãƒ¼ã‚¸ {page}/{args.pages} å–å¾—ä¸­ï¼ˆoffset: {offset}ï¼‰...")
                    
                    api_response = fetch_dmm_ranking(
                        api_id,
                        affiliate_id,
                        keyword=genre_info['keyword'] if not args.genre_id else None,
                        sort="date",
                        hits=args.hits,
                        offset=offset,
                        genre_id=args.genre_id,
                        maker_id=args.maker_id,
                        actress_id=args.actress_id,
                        series_id=args.series_id,
                        price_from=args.price_from,
                        price_to=args.price_to,
                        gte_date=date_from,
                        lte_date=date_to
                    )
                    
                    page_data = extract_ranking_data(api_response, filter_keywords=genre_info['filter_keywords'])
                    all_items.extend(page_data)
                    
                    # ãƒšãƒ¼ã‚¸é–“ã§å°‘ã—å¾…æ©Ÿ
                    if page < args.pages:
                        time.sleep(1)
            
            # é‡è¤‡ã‚’é™¤å»ï¼ˆcontent_idã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ï¼‰
            seen_ids = set()
            unique_items = []
            for item in all_items:
                if item.get("content_id") not in seen_ids:
                    seen_ids.add(item.get("content_id"))
                    unique_items.append(item)
            
            ranking_data = unique_items
            print(f"   ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‰: {len(ranking_data)}ä»¶ï¼ˆé‡è¤‡é™¤å»å¾Œï¼‰")
            
            # ç†Ÿå¥³ãƒ»äººå¦»ãƒ»ãƒ‰ãƒ©ãƒä½œå“ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            before_count = len(ranking_data)
            ranking_data = [item for item in ranking_data if is_valid_mature_drama_work(item)]
            after_count = len(ranking_data)
            print(f"   ğŸ“Š ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¾Œ: {after_count}ä»¶ (é™¤å¤–: {before_count - after_count}ä»¶)")
            
            # æ—¢å­˜è¨˜äº‹ã‚’é™¤å¤–
            if args.exclude_existing and existing_content_ids:
                before_exclude = len(ranking_data)
                ranking_data = [item for item in ranking_data if item.get("content_id") not in existing_content_ids]
                after_exclude = len(ranking_data)
                print(f"   ğŸ“Š æ—¢å­˜è¨˜äº‹é™¤å¤–å¾Œ: {after_exclude}ä»¶ (é™¤å¤–: {before_exclude - after_exclude}ä»¶)")
            
            # ãƒ©ãƒ³ã‚¯ç•ªå·ã‚’æŒ¯ã‚Šç›´ã™
            for idx, item in enumerate(ranking_data, start=1):
                item["rank"] = idx
            
            if not ranking_data:
                print(f"   âš ï¸  {genre_info['name']}ã®ä½œå“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                continue
            
            print(f"   âœ… {len(ranking_data)}ä»¶ã®ä½œå“ã‚’å–å¾—ã—ã¾ã—ãŸ")
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            genre_output_path = output_dir / f"mature_drama_{genre_key}_{timestamp}.json"
            genre_latest_path = output_dir / f"mature_drama_{genre_key}_latest.json"
            
            save_to_json(ranking_data, str(genre_output_path))
            save_to_json(ranking_data, str(genre_latest_path))
            
            all_results[genre_key] = {
                "genre_name": genre_info['name'],
                "data": ranking_data
            }
            
            # TOP5è¡¨ç¤º
            print(f"\n   ğŸ“ˆ {genre_info['name']} TOP5:")
            for item in ranking_data[:5]:
                actresses = "ã€".join(item['actress'][:2]) if item['actress'] else "ä¸æ˜"
                print(f"      {item['rank']:2d}. {item['title'][:40]}... ({actresses})")
            print()
            
            time.sleep(1)  # APIè² è·è»½æ¸›
            
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            continue
    
    # å…¨ã‚¸ãƒ£ãƒ³ãƒ«çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    if len(genres_to_fetch) > 1:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        combined_latest_path = output_dir / "mature_drama_all_latest.json"
        
        # å…¨ã‚¸ãƒ£ãƒ³ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
        all_items = []
        for result in all_results.values():
            all_items.extend(result['data'])
        
        # é‡è¤‡ã‚’é™¤å»ï¼ˆcontent_idã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ï¼‰
        seen_ids = set()
        unique_items = []
        for item in all_items:
            if item['content_id'] not in seen_ids:
                seen_ids.add(item['content_id'])
                unique_items.append(item)
        
        save_to_json(unique_items, str(combined_latest_path))
        print(f"âœ… å…¨ã‚¸ãƒ£ãƒ³ãƒ«çµ±åˆï¼ˆé‡è¤‡é™¤å»å¾Œï¼‰: {len(unique_items)}ä»¶")
    
    print("\n" + "=" * 80)
    print("ğŸ“Š å–å¾—å®Œäº†ã‚µãƒãƒªãƒ¼:")
    print("=" * 80)
    total_count = 0
    for genre_key, result in all_results.items():
        count = len(result['data'])
        total_count += count
        print(f"  {result['genre_name']}: {count}ä»¶")
    print(f"\n  åˆè¨ˆ: {total_count}ä»¶")
    print("=" * 80)
    print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   python3 scripts/bulk_generate_mature_drama_articles.py")
    print()


if __name__ == "__main__":
    main()


