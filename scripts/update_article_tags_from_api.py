#!/usr/bin/env python3
"""
æ—¢å­˜è¨˜äº‹ã®ã‚¿ã‚°ã‚’ã€DMM APIã‹ã‚‰å–å¾—ã—ãŸã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±ã§æ›´æ–°ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import re
import sys
import time
from pathlib import Path
from urllib.parse import urlparse, parse_qs, unquote
import urllib.request
import urllib.error
import ssl

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
try:
    from dotenv import load_dotenv
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    env_path = project_root / ".env"
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {env_path}")
except ImportError:
    print("âš ï¸  python-dotenvãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install python-dotenv ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
except Exception as e:
    print(f"âš ï¸  .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

import os

def fetch_dmm_product_info(api_id: str, affiliate_id: str, content_id: str) -> dict | None:
    """DMM APIã‹ã‚‰ä½œå“æƒ…å ±ã‚’å–å¾—"""
    base_url = "https://api.dmm.com/affiliate/v3/ItemList"
    
    params = {
        "api_id": api_id,
        "affiliate_id": affiliate_id,
        "site": "FANZA",
        "service": "digital",
        "floor": "video",
        "cid": content_id,
        "output": "json"
    }
    
    url = f"{base_url}?{urllib.parse.urlencode(params)}"
    
    try:
        # SSLè¨¼æ˜æ›¸æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé–‹ç™ºç’°å¢ƒã®ã¿ï¼‰
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req, timeout=10, context=ssl_context) as response:
            data = json.loads(response.read().decode('utf-8'))
            
            if "result" in data and "items" in data["result"] and len(data["result"]["items"]) > 0:
                item = data["result"]["items"][0]
                
                return {
                    "content_id": item.get("content_id", ""),
                    "title": item.get("title", ""),
                    "genre": [genre.get("name", "") for genre in item.get("iteminfo", {}).get("genre", [])],
                    "actress": [actress.get("name", "") for actress in item.get("iteminfo", {}).get("actress", [])],
                    "maker": item.get("iteminfo", {}).get("maker", [{}])[0].get("name", "") if item.get("iteminfo", {}).get("maker") else "",
                    "director": item.get("iteminfo", {}).get("director", [{}])[0].get("name", "") if item.get("iteminfo", {}).get("director") else "",
                }
            
    except Exception as e:
        print(f"âš ï¸  APIå–å¾—ã‚¨ãƒ©ãƒ¼ ({content_id}): {e}", file=sys.stderr)
        return None
    
    return None


def parse_markdown_file(file_path: Path) -> dict:
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰frontmatterã‚’è§£æ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # frontmatterã‚’æŠ½å‡º
        match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
        if not match:
            return {}
        
        frontmatter_text = match.group(1)
        frontmatter = {}
        
        # å„è¡Œã‚’ãƒ‘ãƒ¼ã‚¹
        for line in frontmatter_text.split('\n'):
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip()
                value = value.strip().strip('"').strip("'")
                
                # é…åˆ—ã®å‡¦ç†
                if value.startswith('[') and value.endswith(']'):
                    # é…åˆ—ã‹ã‚‰å€¤ã‚’æŠ½å‡º
                    array_content = value[1:-1]
                    array_values = []
                    for item in array_content.split(','):
                        item = item.strip().strip('"').strip("'")
                        if item:
                            array_values.append(item)
                    frontmatter[key] = array_values
                else:
                    frontmatter[key] = value
        
        return frontmatter
        
    except Exception as e:
        print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}", file=sys.stderr)
        return {}


def update_article_tags(file_path: Path, api_genres: list, api_actress: list, api_maker: str) -> bool:
    """è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¿ã‚°ã‚’æ›´æ–°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # frontmatterã‚’æŠ½å‡º
        match = re.match(r'^(---\n.*?\n---)', content, re.DOTALL)
        if not match:
            return False
        
        frontmatter_text = match.group(1)
        rest_content = content[len(frontmatter_text):]
        
        # æ—¢å­˜ã®frontmatterã‚’è§£æ
        existing_frontmatter = parse_markdown_file(file_path)
        existing_tags = existing_frontmatter.get('tags', [])
        
        # æ–°ã—ã„ã‚¿ã‚°ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        new_tags = []
        
        # 1. æ—¢å­˜ã®ã‚¿ã‚°ã‚’ä¿æŒï¼ˆãƒãƒƒãƒã—ãŸã‚¸ãƒ£ãƒ³ãƒ«ã€å¹´ã€å¥³å„ªã€ãƒ¡ãƒ¼ã‚«ãƒ¼ãªã©ï¼‰
        matched_genres = existing_frontmatter.get('genre', [])
        if matched_genres:
            new_tags.extend([f'"{g}"' for g in matched_genres])
        
        # å¹´ã‚’æŠ½å‡º
        year = None
        for tag in existing_tags:
            if isinstance(tag, str) and tag.endswith('å¹´'):
                year = tag
                break
        
        if year:
            new_tags.append(f'"{year}"')
        
        # 2. DMM APIã‹ã‚‰å–å¾—ã—ãŸã™ã¹ã¦ã®ã‚¸ãƒ£ãƒ³ãƒ«ã‚’è¿½åŠ 
        important_genres = ['ä¸­å‡ºã—', 'ä¸­å‡º', 'ãƒ™ãƒ­ãƒãƒ¥ãƒ¼', 'ã‚¬ãƒã‚¤ã‚­', '3P', '4P', 'ä¸å€«', 'NTR', 'ãƒãƒˆãƒ©ãƒ¬', 'å¯å–ã‚‰ã‚Œ']
        
        # é‡è¦ãªã‚¸ãƒ£ãƒ³ãƒ«ã‚’å„ªå…ˆçš„ã«è¿½åŠ 
        for genre in api_genres:
            genre_quoted = f'"{genre}"'
            if any(important in genre for important in important_genres):
                if genre_quoted not in new_tags:
                    new_tags.append(genre_quoted)
        
        # ãã®ä»–ã®ã‚¸ãƒ£ãƒ³ãƒ«ã‚’è¿½åŠ 
        for genre in api_genres:
            genre_quoted = f'"{genre}"'
            if genre_quoted not in new_tags:
                new_tags.append(genre_quoted)
        
        # 3. å¥³å„ªã‚¿ã‚°ï¼ˆæœ€å¤§2äººã¾ã§ã€æ—¢å­˜ã®ã‚‚ã®ã‚’å„ªå…ˆï¼‰
        existing_actress_tags = [t for t in existing_tags if isinstance(t, str) and t in api_actress]
        if existing_actress_tags:
            new_tags.extend([f'"{a}"' for a in existing_actress_tags[:2]])
        elif api_actress:
            new_tags.extend([f'"{a}"' for a in api_actress[:2]])
        
        # 4. ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚¿ã‚°
        if api_maker:
            maker_quoted = f'"{api_maker}"'
            if maker_quoted not in new_tags:
                new_tags.append(maker_quoted)
        
        # ã‚¿ã‚°æ•°ã‚’15å€‹ã¾ã§ã«åˆ¶é™
        new_tags = new_tags[:15]
        tags_str = ", ".join(new_tags)
        
        # frontmatterã‚’æ›´æ–°
        tags_pattern = r'tags:\s*\[.*?\]'
        if re.search(tags_pattern, frontmatter_text):
            new_frontmatter = re.sub(tags_pattern, f'tags: [{tags_str}]', frontmatter_text)
        else:
            # tagsè¡ŒãŒãªã„å ´åˆã¯è¿½åŠ 
            new_frontmatter = frontmatter_text.rstrip() + f'\ntags: [{tags_str}]\n---'
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿
        new_content = new_frontmatter + rest_content
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        return True
        
    except Exception as e:
        print(f"âš ï¸  ã‚¿ã‚°æ›´æ–°ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}", file=sys.stderr)
        return False


def extract_content_id_from_url(url: str) -> str:
    """ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆURLã‹ã‚‰content_idã‚’æŠ½å‡º"""
    try:
        parsed = urlparse(url)
        if 'lurl' in parse_qs(parsed.query):
            lurl = parse_qs(parsed.query)['lurl'][0]
            decoded_lurl = unquote(lurl)
            match = re.search(r'id=([^&/]+)', decoded_lurl)
            if match:
                return match.group(1)
        match = re.search(r'id=([^&/]+)', url)
        if match:
            return match.group(1)
    except Exception as e:
        print(f"âš ï¸  URLè§£æã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
    return None


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    content_dir = project_root / "content"
    
    if not content_dir.exists():
        print(f"âŒ contentãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {content_dir}")
        sys.exit(1)
    
    # DMM APIèªè¨¼æƒ…å ±
    api_id = os.getenv("DMM_API_ID")
    affiliate_id = os.getenv("DMM_AFFILIATE_ID")
    
    if not api_id or not affiliate_id:
        print("âŒ DMM_API_IDã¾ãŸã¯DMM_AFFILIATE_IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    # ã™ã¹ã¦ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    md_files = sorted(content_dir.glob("*.md"))
    
    print(f"ğŸ“ è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(md_files)}ä»¶")
    print("=" * 80)
    
    updated_count = 0
    error_count = 0
    skipped_count = 0
    
    for idx, md_file in enumerate(md_files, 1):
        print(f"\n[{idx}/{len(md_files)}] {md_file.name} ã‚’å‡¦ç†ä¸­...")
        
        # frontmatterã‚’è§£æ
        frontmatter = parse_markdown_file(md_file)
        
        # content_idã‚’å–å¾—
        content_id = frontmatter.get('contentId', '')
        affiliate_link = frontmatter.get('affiliateLink', '')
        
        if not content_id and affiliate_link:
            content_id = extract_content_id_from_url(affiliate_link)
        
        if not content_id:
            print(f"   âš ï¸  content_idãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            error_count += 1
            continue
        
        # DMM APIã‹ã‚‰ä½œå“æƒ…å ±ã‚’å–å¾—
        product_info = fetch_dmm_product_info(api_id, affiliate_id, content_id)
        
        if not product_info:
            print(f"   âš ï¸  ä½œå“æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            error_count += 1
            continue
        
        api_genres = product_info.get('genre', [])
        
        if not api_genres:
            print(f"   âš ï¸  ã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
            skipped_count += 1
            continue
        
        # ã‚¿ã‚°ã‚’æ›´æ–°
        if update_article_tags(md_file, api_genres, product_info.get('actress', []), product_info.get('maker', '')):
            print(f"   âœ… ã‚¿ã‚°ã‚’æ›´æ–°ã—ã¾ã—ãŸï¼ˆã‚¸ãƒ£ãƒ³ãƒ«: {len(api_genres)}ä»¶ï¼‰")
            updated_count += 1
        else:
            print(f"   âš ï¸  ã‚¿ã‚°ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
            error_count += 1
        
        # APIè² è·è»½æ¸›ã®ãŸã‚ã€å°‘ã—å¾…æ©Ÿ
        time.sleep(1)
    
    # çµæœã‚’è¡¨ç¤º
    print("\n" + "=" * 80)
    print("ğŸ“Š æ›´æ–°çµæœ")
    print("=" * 80)
    print(f"âœ… æ›´æ–°å®Œäº†: {updated_count}ä»¶")
    print(f"âš ï¸  ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶")
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
    print("=" * 80)


if __name__ == "__main__":
    main()

