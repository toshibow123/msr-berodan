#!/usr/bin/env python3
"""
MGSè¨˜äº‹ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLã‚’æ­£ã—ã„å½¢å¼ã«ä¿®æ­£ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
cap_e_{ç”»åƒç•ªå·}_{å•†å“ID}.jpg ã®å½¢å¼ã«ä¿®æ­£
"""

import re
import json
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
script_dir = Path(__file__).parent
project_root = script_dir.parent
content_dir = project_root / "content"

def extract_frontmatter(content: str) -> tuple[dict, str]:
    """ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡º"""
    if not content.startswith("---"):
        return {}, content
    
    end_pos = content.find("\n---", 3)
    if end_pos == -1:
        return {}, content
    
    frontmatter_text = content[4:end_pos].strip()
    body = content[end_pos + 5:].strip()
    
    frontmatter = {}
    for line in frontmatter_text.split("\n"):
        if ":" in line:
            key, value = line.split(":", 1)
            key = key.strip()
            value = value.strip().strip('"')
            frontmatter[key] = value
    
    return frontmatter, body

def generate_mgs_sample_image_urls(image_url: str, content_id: str, count: int = 3) -> list[str]:
    """
    MGSã®ãƒ¡ã‚¤ãƒ³ç”»åƒURLã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLã‚’ç”Ÿæˆ
    å½¢å¼: https://image.mgstage.com/images/{maker}/{series}/{id}/cap_e_{ç”»åƒç•ªå·}_{å•†å“ID}.jpg
    
    ä¾‹:
    ãƒ¡ã‚¤ãƒ³ç”»åƒ: https://image.mgstage.com/images/ntrnet/348ntr/082/pf_o2_348ntr-082.jpg
    ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ: https://image.mgstage.com/images/ntrnet/348ntr/082/cap_e_1_348ntr-082.jpg
                 https://image.mgstage.com/images/ntrnet/348ntr/082/cap_e_2_348ntr-082.jpg
                 https://image.mgstage.com/images/ntrnet/348ntr/082/cap_e_3_348ntr-082.jpg
    """
    if not image_url or "image.mgstage.com" not in image_url:
        return []
    
    # ãƒ¡ã‚¤ãƒ³ç”»åƒURLã‹ã‚‰ãƒ‘ã‚¹æ§‹é€ ã‚’æŠ½å‡º
    # ä¾‹: https://image.mgstage.com/images/ntrnet/348ntr/082/pf_o2_348ntr-082.jpg
    match = re.search(r'https://image\.mgstage\.com/images/(.+?)/(.+?)/(.+?)/', image_url)
    if not match:
        return []
    
    maker = match.group(1)
    series = match.group(2)
    id_part = match.group(3)
    
    # content_idã‚’å°æ–‡å­—ã«å¤‰æ›ï¼ˆ348NTR-082 -> 348ntr-082ï¼‰
    content_id_lower = content_id.lower()
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLã‚’ç”Ÿæˆ
    sample_urls = []
    for i in range(1, count + 1):
        sample_url = f"https://image.mgstage.com/images/{maker}/{series}/{id_part}/cap_e_{i}_{content_id_lower}.jpg"
        sample_urls.append(sample_url)
    
    return sample_urls

def fix_sample_image_urls_in_body(body: str, image_url: str, content_id: str) -> str:
    """æœ¬æ–‡å†…ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLã‚’ä¿®æ­£"""
    # ç¾åœ¨ã®é–“é•ã£ãŸURLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å…¨ã¦æ¢ã—ã¦ç½®ãæ›ãˆã‚‹
    # pf_o2_348ntr-082-1.jpg ã‚„ pf_348ntr-082-1.jpg ã®å½¢å¼ã‚’ cap_e_1_348ntr-082.jpg ã«ä¿®æ­£
    
    # ãƒ¡ã‚¤ãƒ³ç”»åƒURLã‹ã‚‰ãƒ‘ã‚¹æ§‹é€ ã‚’æŠ½å‡º
    match = re.search(r'https://image\.mgstage\.com/images/(.+?)/(.+?)/(.+?)/', image_url)
    if not match:
        return body
    
    maker = match.group(1)
    series = match.group(2)
    id_part = match.group(3)
    content_id_lower = content_id.lower()
    
    # æ—¢å­˜ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å…¨ã¦ç½®ãæ›ãˆ
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: pf_o2_348ntr-082-1.jpg
    pattern1 = rf'https://image\.mgstage\.com/images/{re.escape(maker)}/{re.escape(series)}/{re.escape(id_part)}/pf_o2_[^/]+-(\d+)\.jpg'
    def replace1(m):
        num = m.group(1)
        return f'https://image.mgstage.com/images/{maker}/{series}/{id_part}/cap_e_{num}_{content_id_lower}.jpg'
    body = re.sub(pattern1, replace1, body)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: pf_348ntr-082-1.jpg
    pattern2 = rf'https://image\.mgstage\.com/images/{re.escape(maker)}/{re.escape(series)}/{re.escape(id_part)}/pf_[^/]+-(\d+)\.jpg'
    def replace2(m):
        num = m.group(1)
        return f'https://image.mgstage.com/images/{maker}/{series}/{id_part}/cap_e_{num}_{content_id_lower}.jpg'
    body = re.sub(pattern2, replace2, body)
    
    return body

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("  MGSè¨˜äº‹ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLä¿®æ­£ï¼ˆcap_eå½¢å¼ï¼‰")
    print("=" * 80 + "\n")
    
    mgs_articles = list(content_dir.glob("2026-01-02-*.md"))
    
    if not mgs_articles:
        print("âŒ ä¿®æ­£å¯¾è±¡ã®è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ“‹ {len(mgs_articles)}ä»¶ã®è¨˜äº‹ã‚’ä¿®æ­£ã—ã¾ã™\n")
    
    fixed_count = 0
    skipped_count = 0
    
    for article_file in mgs_articles:
        try:
            with open(article_file, "r", encoding="utf-8") as f:
                content = f.read()
            
            frontmatter, body = extract_frontmatter(content)
            
            if not frontmatter:
                print(f"â­ï¸  {article_file.name} - ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                skipped_count += 1
                continue
            
            source = frontmatter.get("source", "")
            if source != "MGS":
                print(f"â­ï¸  {article_file.name} - MGSè¨˜äº‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                skipped_count += 1
                continue
            
            image_url = frontmatter.get("image", "")
            content_id = frontmatter.get("contentId", "")
            
            if not image_url or not content_id:
                print(f"â­ï¸  {article_file.name} - å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                skipped_count += 1
                continue
            
            # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒURLã‚’ä¿®æ­£
            new_body = fix_sample_image_urls_in_body(body, image_url, content_id)
            
            # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’å†æ§‹ç¯‰
            frontmatter_lines = ["---"]
            frontmatter_lines.append(f'title: "{frontmatter.get("title", "").replace('"', '\\"')}"')
            frontmatter_lines.append(f'date: "{frontmatter.get("date", "")}"')
            frontmatter_lines.append(f'excerpt: "{frontmatter.get("excerpt", "").replace('"', '\\"')}"')
            frontmatter_lines.append(f'image: "{frontmatter.get("image", "")}"')
            
            # tagsã‚’æ­£ã—ãå‡¦ç†
            tags = frontmatter.get("tags", [])
            if isinstance(tags, str):
                try:
                    tags = json.loads(tags)
                except:
                    tags = []
            frontmatter_lines.append(f'tags: {json.dumps(tags, ensure_ascii=False)}')
            
            frontmatter_lines.append(f'affiliateLink: "{frontmatter.get("affiliateLink", "")}"')
            frontmatter_lines.append(f'contentId: "{frontmatter.get("contentId", "")}"')
            frontmatter_lines.append(f'rating: {frontmatter.get("rating", "4.0")}')
            frontmatter_lines.append(f'source: "MGS"')
            frontmatter_lines.append("---")
            
            new_content = "\n".join(frontmatter_lines) + "\n\n" + new_body
            
            with open(article_file, "w", encoding="utf-8") as f:
                f.write(new_content)
            
            print(f"âœ… {article_file.name} - ä¿®æ­£å®Œäº†")
            fixed_count += 1
                
        except Exception as e:
            print(f"âŒ {article_file.name} - ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 80)
    print(f"ğŸ‰ ä¿®æ­£å®Œäº†ï¼")
    print(f"   ä¿®æ­£: {fixed_count}ä»¶")
    print(f"   ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶")
    print("=" * 80)

if __name__ == "__main__":
    main()

