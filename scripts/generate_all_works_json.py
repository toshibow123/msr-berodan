#!/usr/bin/env python3
"""
content/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ã€
data/all_works.jsonã«ã¾ã¨ã‚ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import json
import re
from pathlib import Path
from typing import Dict, List, Optional

def parse_frontmatter(content: str) -> Dict[str, any]:
    """ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’ãƒ‘ãƒ¼ã‚¹"""
    frontmatter = {}
    
    # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã®é–‹å§‹ã¨çµ‚äº†ã‚’æ¤œå‡º
    if not content.startswith("---"):
        return frontmatter
    
    # æœ€åˆã®`---`ã‹ã‚‰æ¬¡ã®`---`ã¾ã§ã‚’æŠ½å‡º
    end_index = content.find("---", 3)
    if end_index == -1:
        return frontmatter
    
    frontmatter_text = content[3:end_index].strip()
    
    # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º
    patterns = {
        'title': r'title:\s*"([^"]+)"',
        'date': r'date:\s*"([^"]+)"',
        'image': r'image:\s*"([^"]+)"',
        'affiliateLink': r'affiliateLink:\s*"([^"]+)"',
    }
    
    for key, pattern in patterns.items():
        match = re.search(pattern, frontmatter_text)
        if match:
            frontmatter[key] = match.group(1)
    
    return frontmatter

def extract_video_url(content: str) -> Optional[str]:
    """æœ¬æ–‡ã‹ã‚‰videoUrlï¼ˆiframeã®srcï¼‰ã‚’æŠ½å‡º"""
    # iframeã®srcå±æ€§ã‚’æŠ½å‡º
    pattern = r'<iframe[^>]*src="([^"]+)"[^>]*>'
    match = re.search(pattern, content)
    if match:
        return match.group(1)
    return None

def extract_actress(content: str) -> Optional[str]:
    """æœ¬æ–‡ã‹ã‚‰actressï¼ˆå‡ºæ¼”æƒ…å ±ï¼‰ã‚’æŠ½å‡º"""
    # ã€Œ**å‡ºæ¼”:**ã€ã¾ãŸã¯ã€Œ**ä¸»è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼:**ã€ã®è¡Œã‚’æŠ½å‡º
    patterns = [
        r'\*\*å‡ºæ¼”:\*\*\s*(.+?)(?:\n|$)',
        r'\*\*ä¸»è¦ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼:\*\*\s*(.+?)(?:\n|$)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, content)
        if match:
            actress = match.group(1).strip()
            # ã€Œä¸æ˜ã€ã®å ´åˆã¯Noneã‚’è¿”ã™
            if actress and actress != "ä¸æ˜":
                return actress
    
    return None

def parse_markdown_file(file_path: Path) -> Optional[Dict[str, any]]:
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡º"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’ãƒ‘ãƒ¼ã‚¹
        frontmatter = parse_frontmatter(content)
        
        # å¿…è¦ãªé …ç›®ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
        if not all(key in frontmatter for key in ['title', 'date', 'image', 'affiliateLink']):
            print(f"âš ï¸  è­¦å‘Š: {file_path.name} ã«å¿…è¦ãªãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return None
        
        # æœ¬æ–‡ã‹ã‚‰videoUrlã¨actressã‚’æŠ½å‡º
        video_url = extract_video_url(content)
        actress = extract_actress(content)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        work_data = {
            'title': frontmatter['title'],
            'image': frontmatter['image'],
            'videoUrl': video_url,
            'actress': actress,
            'date': frontmatter['date'],
            'affiliateLink': frontmatter['affiliateLink'],
        }
        
        return work_data
    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {file_path.name} ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ãƒ‘ã‚¹ã‚’è¨­å®š
    content_dir = Path(__file__).parent.parent / 'content'
    output_file = Path(__file__).parent.parent / 'data' / 'all_works.json'
    
    # contentãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    if not content_dir.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {content_dir} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return
    
    # dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    # ã™ã¹ã¦ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    md_files = list(content_dir.glob('*.md'))
    print(f"ğŸ“ {len(md_files)}å€‹ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ")
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
    all_works = []
    success_count = 0
    error_count = 0
    
    for md_file in md_files:
        work_data = parse_markdown_file(md_file)
        if work_data:
            all_works.append(work_data)
            success_count += 1
        else:
            error_count += 1
    
    # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    all_works.sort(key=lambda x: x['date'], reverse=True)
    
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_works, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å®Œäº†!")
    print(f"   - æˆåŠŸ: {success_count}ä»¶")
    print(f"   - ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
    print(f"   - å‡ºåŠ›å…ˆ: {output_file}")
    print(f"   - ç·ä»¶æ•°: {len(all_works)}ä»¶")

if __name__ == '__main__':
    main()

