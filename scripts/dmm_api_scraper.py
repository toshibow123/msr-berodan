#!/usr/bin/env python3
"""
DMM API ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ€ãƒ«ãƒˆå‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

è¦ä»¶:
- ç‰¹å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆç†Ÿå¥³ã€äººå¦»ç­‰ï¼‰ã‚’å«ã‚€ä½œå“ã‚’æ¤œç´¢
- ãƒ™ã‚¹ãƒˆãƒ»ç·é›†ç·¨ã‚’é™¤å¤–
- å¥³å„ªåãŒå­˜åœ¨ã™ã‚‹ä½œå“ã®ã¿ã‚’å¯¾è±¡
- é‡è¤‡é™¤å»ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
"""

import os
import json
import time
import requests
from typing import List, Dict, Set, Optional
from datetime import datetime
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ï¼ˆè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ï¼‰
load_dotenv('../.env')

class DMMAPIScraper:
    def __init__(self):
        """DMM API ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®åˆæœŸåŒ–"""
        self.api_id = os.getenv('DMM_API_ID')
        self.affiliate_id = os.getenv('DMM_AFFILIATE_ID')
        
        if not self.api_id or not self.affiliate_id:
            raise ValueError("DMM_API_ID ã¨ DMM_AFFILIATE_ID ã‚’ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã—ã¦ãã ã•ã„")
        
        # DMM API v3 å…¬å¼ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆå¹´é½¢èªè¨¼å¯¾å¿œï¼‰
        self.base_url = "https://api.dmm.com/affiliate/v3/ItemList"
        self.collected_ids: Set[str] = set()  # é‡è¤‡é˜²æ­¢ç”¨
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šï¼ˆå¹´é½¢èªè¨¼çªç ´ç”¨ï¼‰
        self.session = requests.Session()
        self.setup_session()
        
        # æ¤œç´¢å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆåŒ…å«ã‚¿ã‚°ï¼‰
        self.include_keywords = [
            'ãŠæ¯ã•ã‚“', 'å¥³å°†ãƒ»å¥³ä¸»äºº', 'ç¾©æ¯', 'ç†Ÿå¥³', 
            'å¯å–ã‚Šãƒ»å¯å–ã‚‰ã‚Œãƒ»NTR', 'äººå¦»ãƒ»ä¸»å©¦', 'æœªäº¡äºº', 
            'ãƒãƒå‹', 'è‹¥å¦»ãƒ»å¹¼å¦»', 'å¦Šå©¦', 'ãƒ‰ãƒ©ãƒ'
        ]
        
        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.exclude_keywords = ['ãƒ™ã‚¹ãƒˆãƒ»ç·é›†ç·¨', 'ãƒ™ã‚¹ãƒˆ', 'ç·é›†ç·¨']
        
        print(f"ğŸš€ DMM API ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“‹ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(self.include_keywords)}")
        print(f"ğŸš« é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(self.exclude_keywords)}")

    def setup_session(self):
        """
        å¹´é½¢èªè¨¼çªç ´ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š
        """
        # å¹´é½¢èªè¨¼çªç ´ç”¨ã®ãƒ˜ãƒƒãƒ€ãƒ¼
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/html, application/xhtml+xml, application/xml;q=0.9, */*;q=0.8',
            'Accept-Language': 'ja-JP,ja;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        }
        
        # å¹´é½¢èªè¨¼çªç ´ç”¨ã®Cookie
        cookies = {
            'age_check_done': '1',
            'ckcy': '1',
            'cklg': 'ja',
            'region': 'JP',
            'timezone': 'Asia/Tokyo',
            'adult_check_done': '1',
            'over18': '1'
        }
        
        self.session.headers.update(headers)
        
        # Cookieã‚’å€‹åˆ¥ã«è¨­å®šï¼ˆé‡è¤‡å›é¿ï¼‰
        for name, value in cookies.items():
            self.session.cookies.set(name, value, domain='.dmm.com')
        
        print(f"ğŸª å¹´é½¢èªè¨¼Cookieè¨­å®šå®Œäº†: {len(cookies)}å€‹ã®Cookieã‚’è¨­å®š")
        
        # äº‹å‰ã«å¹´é½¢èªè¨¼ã‚’çªç ´
        self.bypass_age_verification()

    def bypass_age_verification(self):
        """
        äº‹å‰ã«å¹´é½¢èªè¨¼ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦Cookieã‚’ç¢ºå®Ÿã«è¨­å®š
        """
        try:
            print(f"ğŸ”“ å¹´é½¢èªè¨¼çªç ´ã‚’å®Ÿè¡Œä¸­...")
            
            # DMM ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            dmm_top = "https://www.dmm.co.jp/"
            response = self.session.get(dmm_top, timeout=10)
            
            if response.status_code == 200:
                print(f"âœ… DMM ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ")
                
                # å¹´é½¢èªè¨¼ãƒšãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚ŒãŸå ´åˆã®å‡¦ç†
                if 'age_check' in response.url or 'rating' in response.url:
                    print(f"ğŸš« å¹´é½¢èªè¨¼ãƒšãƒ¼ã‚¸ã‚’æ¤œå‡ºã€çªç ´ã‚’è©¦è¡Œ...")
                    
                    # å¹´é½¢èªè¨¼ãƒ•ã‚©ãƒ¼ãƒ ã®é€ä¿¡ã‚’æ¨¡æ“¬
                    age_check_data = {
                        'age_check_done': '1',
                        'redirect_url': '/',
                        'submit': 'åŒæ„ã™ã‚‹'
                    }
                    
                    age_response = self.session.post(
                        response.url,
                        data=age_check_data,
                        timeout=10,
                        allow_redirects=True
                    )
                    
                    if age_response.status_code == 200:
                        print(f"âœ… å¹´é½¢èªè¨¼çªç ´æˆåŠŸ")
                    else:
                        print(f"âš ï¸  å¹´é½¢èªè¨¼çªç ´ã«å¤±æ•—: {age_response.status_code}")
                else:
                    print(f"âœ… å¹´é½¢èªè¨¼ã¯ä¸è¦ã§ã—ãŸ")
                    
            else:
                print(f"âš ï¸  DMM ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {response.status_code}")
                
        except Exception as e:
            print(f"âš ï¸  å¹´é½¢èªè¨¼çªç ´ã§ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ğŸ’¡ Cookieã«ã‚ˆã‚‹èªè¨¼ã‚’ç¶™ç¶šã—ã¾ã™")

    def search_videos(self, keyword: str, offset: int = 1, hits: int = 100) -> Optional[Dict]:
        """
        æŒ‡å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å‹•ç”»ã‚’æ¤œç´¢
        
        Args:
            keyword: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            offset: æ¤œç´¢é–‹å§‹ä½ç½®
            hits: å–å¾—ä»¶æ•°ï¼ˆæœ€å¤§100ï¼‰
        
        Returns:
            APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆè¾æ›¸å½¢å¼ï¼‰ã¾ãŸã¯None
        """
        params = {
            'api_id': self.api_id,
            'affiliate_id': self.affiliate_id,
            'site': 'FANZA',
            'service': 'digital',
            'floor': 'videoa',  # ã‚¢ãƒ€ãƒ«ãƒˆå‹•ç”»ãƒ•ãƒ­ã‚¢
            'hits': min(hits, 100),  # æœ€å¤§100ä»¶
            'offset': offset,
            'keyword': keyword,
            'output': 'json',
            'sort': 'date'  # ç™ºå£²æ—¥é †ã§ã‚½ãƒ¼ãƒˆ
        }
        
        try:
            print(f"ğŸ” æ¤œç´¢ä¸­: '{keyword}' (offset: {offset})")
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå›ºæœ‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
            request_headers = {
                'Referer': 'https://www.dmm.co.jp/',
                'Origin': 'https://www.dmm.co.jp'
            }
            
            # æ—¢å­˜ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¿½åŠ 
            temp_headers = self.session.headers.copy()
            temp_headers.update(request_headers)
            
            response = self.session.get(
                self.base_url, 
                params=params,
                headers=request_headers,
                timeout=30,
                allow_redirects=True
            )
            
            print(f"ğŸ“¡ ãƒªã‚¯ã‚¨ã‚¹ãƒˆURL: {response.url}")
            print(f"ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
            
            # Cookieæƒ…å ±ã‚’å®‰å…¨ã«è¡¨ç¤ºï¼ˆé‡è¤‡å›é¿ï¼‰
            cookie_info = []
            for cookie in self.session.cookies:
                cookie_info.append(f"{cookie.name}={cookie.value}")
            print(f"ğŸª é€ä¿¡Cookie: {'; '.join(cookie_info)}")
            
            response.raise_for_status()
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã®è©³ç´°ãƒã‚§ãƒƒã‚¯
            content_type = response.headers.get('Content-Type', '')
            print(f"ğŸ“‹ Content-Type: {content_type}")
            
            # HTMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å ´åˆï¼ˆå¹´é½¢èªè¨¼ãƒšãƒ¼ã‚¸ãªã©ï¼‰
            if 'text/html' in content_type:
                print(f"âš ï¸  HTMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ï¼ˆå¹´é½¢èªè¨¼ãƒšãƒ¼ã‚¸ã®å¯èƒ½æ€§ï¼‰")
                
                # HTMLã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡ºã—ã¦ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¨ã—ã¦è¡¨ç¤º
                html_content = response.text
                title_start = html_content.find('<title>')
                title_end = html_content.find('</title>')
                
                if title_start != -1 and title_end != -1:
                    title = html_content[title_start + 7:title_end]
                    print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: {title}")
                
                # å¹´é½¢èªè¨¼é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
                age_check_keywords = ['å¹´é½¢ç¢ºèª', '18æ­³ä»¥ä¸Š', 'age verification', 'rating']
                for keyword in age_check_keywords:
                    if keyword in html_content:
                        print(f"ğŸš« å¹´é½¢èªè¨¼ãƒšãƒ¼ã‚¸ã‚’æ¤œå‡º: '{keyword}' ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
                        break
                
                print(f"ğŸ“„ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
                print(f"{html_content[:500]}...")
                return None
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†
            try:
                data = response.json()
            except json.JSONDecodeError as json_error:
                print(f"âŒ JSON ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {json_error}")
                print(f"ğŸ“„ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
                print(f"{response.text[:500]}...")
                
                # XMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å¯èƒ½æ€§ã‚‚ãƒã‚§ãƒƒã‚¯
                if response.text.strip().startswith('<?xml'):
                    print(f"ğŸ“‹ XMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ¤œå‡º")
                elif response.text.strip().startswith('<html'):
                    print(f"ğŸ“‹ HTMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ¤œå‡º")
                
                return None
            
            # APIã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒã‚§ãƒƒã‚¯
            if 'error' in data:
                error_info = data['error']
                print(f"âŒ API ã‚¨ãƒ©ãƒ¼: {error_info}")
                
                # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ãŒã‚ã‚Œã°è¡¨ç¤º
                if isinstance(error_info, dict):
                    error_code = error_info.get('code', 'Unknown')
                    error_message = error_info.get('message', 'No message')
                    print(f"   ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰: {error_code}")
                    print(f"   ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {error_message}")
                
                return None
            
            # æ­£å¸¸ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†
            if 'result' in data and 'items' in data['result']:
                total_count = data['result'].get('total_count', 0)
                items_count = len(data['result']['items'])
                print(f"âœ… å–å¾—æˆåŠŸ: {items_count}ä»¶ (ç·ä»¶æ•°: {total_count}ä»¶)")
                return data
            else:
                print(f"âš ï¸  æ¤œç´¢çµæœãªã—: '{keyword}'")
                print(f"ğŸ“‹ ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ : {list(data.keys()) if data else 'Empty'}")
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã®è©³ç´°ã‚’è¡¨ç¤º
                if data:
                    for key, value in data.items():
                        if isinstance(value, dict):
                            print(f"   {key}: {list(value.keys())}")
                        elif isinstance(value, list):
                            print(f"   {key}: ãƒªã‚¹ãƒˆï¼ˆ{len(value)}ä»¶ï¼‰")
                        else:
                            print(f"   {key}: {type(value).__name__}")
                
                return None
                
        except requests.exceptions.ConnectionError as e:
            print(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            print(f"ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã¾ãŸã¯DNSè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            return None
        except requests.exceptions.Timeout as e:
            print(f"âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
        except requests.exceptions.RequestException as e:
            print(f"âŒ API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def is_valid_item(self, item: Dict) -> bool:
        """
        ã‚¢ã‚¤ãƒ†ãƒ ãŒå–å¾—æ¡ä»¶ã‚’æº€ãŸã™ã‹ãƒã‚§ãƒƒã‚¯
        
        Args:
            item: APIã‹ã‚‰å–å¾—ã—ãŸã‚¢ã‚¤ãƒ†ãƒ ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            æœ‰åŠ¹ãªå ´åˆTrue
        """
        # content_id ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        content_id = item.get('content_id', '')
        if content_id in self.collected_ids:
            return False
        
        # å¥³å„ªåã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        actresses = item.get('iteminfo', {}).get('actress', [])
        if not actresses or len(actresses) == 0:
            return False
        
        # å¥³å„ªåãŒç©ºã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
        valid_actresses = [a for a in actresses if a.get('name', '').strip()]
        if not valid_actresses:
            return False
        
        # ã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±ã®å–å¾—
        genres = item.get('iteminfo', {}).get('genre', [])
        genre_names = [g.get('name', '') for g in genres]
        
        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
        for exclude_keyword in self.exclude_keywords:
            if any(exclude_keyword in genre_name for genre_name in genre_names):
                print(f"ğŸš« é™¤å¤–: {item.get('title', 'Unknown')} (ç†ç”±: {exclude_keyword})")
                return False
        
        return True

    def extract_item_data(self, item: Dict) -> Dict:
        """
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Args:
            item: APIã‹ã‚‰å–å¾—ã—ãŸã‚¢ã‚¤ãƒ†ãƒ ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        # åŸºæœ¬æƒ…å ±
        content_id = item.get('content_id', '')
        title = item.get('title', '')
        
        # å¥³å„ªåã®æŠ½å‡º
        actresses = item.get('iteminfo', {}).get('actress', [])
        actress_names = [a.get('name', '') for a in actresses if a.get('name', '').strip()]
        
        # ã‚¸ãƒ£ãƒ³ãƒ«æƒ…å ±ã®æŠ½å‡º
        genres = item.get('iteminfo', {}).get('genre', [])
        genre_names = [g.get('name', '') for g in genres]
        
        # ç”»åƒURL
        package_images = item.get('imageURL', {})
        package_url = package_images.get('large', '') or package_images.get('medium', '') or package_images.get('small', '')
        
        # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ
        sample_images = item.get('sampleImageURL', {}).get('sample_s', {}).get('image', [])
        
        # ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆURL
        affiliate_url = item.get('affiliateURL', '')
        
        # ç™ºå£²æ—¥
        date = item.get('date', '')
        
        return {
            'content_id': content_id,
            'title': title,
            'actress': ', '.join(actress_names),
            'actresses': actress_names,
            'genres': genre_names,
            'package_image': package_url,
            'sample_images': sample_images,
            'affiliate_url': affiliate_url,
            'date': date,
            'collected_at': datetime.now().isoformat()
        }

    def collect_all_videos(self, max_per_keyword: int = 500) -> List[Dict]:
        """
        å…¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
        
        Args:
            max_per_keyword: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚ãŸã‚Šã®æœ€å¤§å–å¾—ä»¶æ•°
        
        Returns:
            åé›†ã•ã‚ŒãŸãƒ“ãƒ‡ã‚ªãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        all_videos = []
        
        for keyword in self.include_keywords:
            print(f"\nğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' ã®æ¤œç´¢é–‹å§‹")
            
            offset = 1
            keyword_count = 0
            
            while keyword_count < max_per_keyword:
                # API ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
                time.sleep(1)  # 1ç§’å¾…æ©Ÿ
                
                # æ¤œç´¢å®Ÿè¡Œ
                response_data = self.search_videos(keyword, offset=offset, hits=100)
                
                if not response_data or 'result' not in response_data:
                    print(f"âš ï¸  '{keyword}' ã®æ¤œç´¢çµ‚äº†ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
                    break
                
                items = response_data['result'].get('items', [])
                if not items:
                    print(f"âš ï¸  '{keyword}' ã®æ¤œç´¢çµ‚äº†ï¼ˆã‚¢ã‚¤ãƒ†ãƒ ãªã—ï¼‰")
                    break
                
                # ã‚¢ã‚¤ãƒ†ãƒ ã®å‡¦ç†
                valid_items = 0
                for item in items:
                    if self.is_valid_item(item):
                        video_data = self.extract_item_data(item)
                        all_videos.append(video_data)
                        self.collected_ids.add(video_data['content_id'])
                        valid_items += 1
                        keyword_count += 1
                        
                        if keyword_count >= max_per_keyword:
                            break
                
                print(f"ğŸ“Š '{keyword}': {valid_items}ä»¶ã®æœ‰åŠ¹ãªã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ  (ç´¯è¨ˆ: {len(all_videos)}ä»¶)")
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸
                offset += len(items)
                
                # å–å¾—ä»¶æ•°ãŒ100ä»¶æœªæº€ã®å ´åˆã¯æœ€å¾Œã®ãƒšãƒ¼ã‚¸
                if len(items) < 100:
                    print(f"âœ… '{keyword}' ã®æ¤œç´¢å®Œäº†ï¼ˆæœ€çµ‚ãƒšãƒ¼ã‚¸ï¼‰")
                    break
        
        print(f"\nğŸ‰ å…¨æ¤œç´¢å®Œäº†! ç·å–å¾—ä»¶æ•°: {len(all_videos)}ä»¶")
        return all_videos

    def save_to_json(self, videos: List[Dict], filename: str = 'actress_videos.json'):
        """
        åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            videos: ãƒ“ãƒ‡ã‚ªãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            filename: ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«å
        """
        try:
            # çµ±è¨ˆæƒ…å ±ã®è¿½åŠ 
            metadata = {
                'total_count': len(videos),
                'collected_at': datetime.now().isoformat(),
                'keywords_used': self.include_keywords,
                'excluded_keywords': self.exclude_keywords,
                'unique_actresses': len(set(v['actress'] for v in videos)),
                'videos': videos
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {filename}")
            print(f"ğŸ“Š çµ±è¨ˆ:")
            print(f"   - ç·ä½œå“æ•°: {metadata['total_count']}ä»¶")
            print(f"   - ãƒ¦ãƒ‹ãƒ¼ã‚¯å¥³å„ªæ•°: {metadata['unique_actresses']}äºº")
            
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def display_summary(self, videos: List[Dict]):
        """
        åé›†çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        
        Args:
            videos: ãƒ“ãƒ‡ã‚ªãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        if not videos:
            print("ğŸ“‹ åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print(f"\nğŸ“‹ åé›†ã‚µãƒãƒªãƒ¼")
        print(f"{'='*50}")
        
        # å¥³å„ªåˆ¥ã®ä½œå“æ•°
        actress_count = {}
        genre_count = {}
        
        for video in videos:
            actress = video['actress']
            actress_count[actress] = actress_count.get(actress, 0) + 1
            
            for genre in video['genres']:
                genre_count[genre] = genre_count.get(genre, 0) + 1
        
        # ä¸Šä½å¥³å„ª
        print(f"\nğŸ‘‘ ä½œå“æ•°ä¸Šä½å¥³å„ª (TOP 10):")
        sorted_actresses = sorted(actress_count.items(), key=lambda x: x[1], reverse=True)
        for i, (actress, count) in enumerate(sorted_actresses[:10], 1):
            print(f"   {i:2d}. {actress}: {count}ä½œå“")
        
        # ä¸Šä½ã‚¸ãƒ£ãƒ³ãƒ«
        print(f"\nğŸ·ï¸  äººæ°—ã‚¸ãƒ£ãƒ³ãƒ« (TOP 10):")
        sorted_genres = sorted(genre_count.items(), key=lambda x: x[1], reverse=True)
        for i, (genre, count) in enumerate(sorted_genres[:10], 1):
            print(f"   {i:2d}. {genre}: {count}ä½œå“")
        
        # æœ€æ–°ä½œå“
        print(f"\nğŸ†• æœ€æ–°ä½œå“ (TOP 5):")
        sorted_videos = sorted(videos, key=lambda x: x['date'], reverse=True)
        for i, video in enumerate(sorted_videos[:5], 1):
            print(f"   {i}. {video['title'][:50]}... ({video['actress']}) - {video['date']}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ¬ DMM API ã‚¢ãƒ€ãƒ«ãƒˆå‹•ç”»ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    try:
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®åˆæœŸåŒ–
        scraper = DMMAPIScraper()
        
        # ãƒ‡ãƒ¼ã‚¿åé›†ã®å®Ÿè¡Œ
        print(f"\nğŸš€ ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
        videos = scraper.collect_all_videos(max_per_keyword=200)  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚ãŸã‚Š200ä»¶ã¾ã§
        
        if videos:
            # çµæœã®è¡¨ç¤º
            scraper.display_summary(videos)
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            scraper.save_to_json(videos, 'actress_videos.json')
            
            print(f"\nâœ… å‡¦ç†å®Œäº†!")
        else:
            print(f"\nâš ï¸  åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
