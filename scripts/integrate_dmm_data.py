#!/usr/bin/env python3
"""
DMM APIã§å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’æ—¢å­˜ã®all_works.jsonã«çµ±åˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ©Ÿèƒ½:
- actress_videos.json ã‹ã‚‰æ—¢å­˜ã® all_works.json å½¢å¼ã«å¤‰æ›
- é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
- å¥³å„ªåã®æ­£è¦åŒ–ã¨ãƒãƒƒãƒ”ãƒ³ã‚°
"""

import json
import os
from datetime import datetime
from typing import List, Dict, Set

class DMMDataIntegrator:
    def __init__(self):
        """ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–"""
        self.existing_data_path = '../data/all_works.json'
        self.dmm_data_path = 'actress_videos.json'
        self.output_path = '../data/all_works_updated.json'
        
    def load_existing_data(self) -> List[Dict]:
        """æ—¢å­˜ã®all_works.jsonã‚’èª­ã¿è¾¼ã¿"""
        if not os.path.exists(self.existing_data_path):
            print(f"âš ï¸  æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.existing_data_path}")
            return []
        
        try:
            with open(self.existing_data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(data)}ä»¶")
            return data
        except Exception as e:
            print(f"âŒ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def load_dmm_data(self) -> List[Dict]:
        """DMM APIã§å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        if not os.path.exists(self.dmm_data_path):
            print(f"âŒ DMM ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.dmm_data_path}")
            return []
        
        try:
            with open(self.dmm_data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            videos = data.get('videos', [])
            print(f"âœ… DMM ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(videos)}ä»¶")
            return videos
        except Exception as e:
            print(f"âŒ DMM ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def normalize_actress_name(self, name: str) -> str:
        """å¥³å„ªåã®æ­£è¦åŒ–"""
        # åŸºæœ¬çš„ãªæ­£è¦åŒ–
        normalized = name.strip()
        
        # å…¨è§’ãƒ»åŠè§’ã®çµ±ä¸€
        normalized = normalized.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
        
        return normalized
    
    def convert_dmm_to_works_format(self, dmm_videos: List[Dict]) -> List[Dict]:
        """DMMå½¢å¼ã‹ã‚‰all_works.jsonå½¢å¼ã«å¤‰æ›"""
        converted_works = []
        
        for video in dmm_videos:
            # åŸºæœ¬æƒ…å ±ã®å¤‰æ›
            work = {
                'title': video.get('title', ''),
                'image': video.get('package_image', ''),
                'videoUrl': None,  # DMM APIã‹ã‚‰ã¯å‹•ç”»URLã¯å–å¾—ã§ããªã„
                'actress': self.normalize_actress_name(video.get('actress', '')),
                'date': video.get('date', ''),
                'affiliateLink': video.get('affiliate_url', ''),
                'description': '',  # DMM APIã‹ã‚‰ã¯è©³ç´°èª¬æ˜ã¯å–å¾—ã§ããªã„
                'comment': '',
                'tags': video.get('genres', []),
                'source': 'dmm_api',  # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ˜è¨˜
                'content_id': video.get('content_id', ''),
                'sample_images': video.get('sample_images', [])
            }
            
            converted_works.append(work)
        
        print(f"âœ… DMM ãƒ‡ãƒ¼ã‚¿å¤‰æ›å®Œäº†: {len(converted_works)}ä»¶")
        return converted_works
    
    def find_duplicates(self, existing_works: List[Dict], new_works: List[Dict]) -> Set[str]:
        """é‡è¤‡ã™ã‚‹ä½œå“ã‚’æ¤œå‡º"""
        existing_titles = set()
        existing_content_ids = set()
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã¨content_idã‚’æŠ½å‡º
        for work in existing_works:
            if work.get('title'):
                existing_titles.add(work['title'])
            if work.get('content_id'):
                existing_content_ids.add(work['content_id'])
        
        duplicates = set()
        
        # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã§é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯
        for work in new_works:
            title = work.get('title', '')
            content_id = work.get('content_id', '')
            
            if title in existing_titles or content_id in existing_content_ids:
                duplicates.add(content_id or title)
        
        print(f"ğŸ” é‡è¤‡æ¤œå‡º: {len(duplicates)}ä»¶")
        return duplicates
    
    def merge_data(self, existing_works: List[Dict], new_works: List[Dict]) -> List[Dict]:
        """ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸"""
        duplicates = self.find_duplicates(existing_works, new_works)
        
        # é‡è¤‡ã‚’é™¤ã„ãŸæ–°è¦ãƒ‡ãƒ¼ã‚¿
        unique_new_works = []
        for work in new_works:
            content_id = work.get('content_id', '')
            title = work.get('title', '')
            
            if content_id not in duplicates and title not in duplicates:
                unique_new_works.append(work)
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        merged_works = existing_works + unique_new_works
        
        # æ—¥ä»˜é †ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        merged_works.sort(key=lambda x: x.get('date', ''), reverse=True)
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸å®Œäº†:")
        print(f"   - æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {len(existing_works)}ä»¶")
        print(f"   - æ–°è¦ãƒ‡ãƒ¼ã‚¿: {len(unique_new_works)}ä»¶")
        print(f"   - é‡è¤‡é™¤å¤–: {len(duplicates)}ä»¶")
        print(f"   - çµ±åˆå¾Œ: {len(merged_works)}ä»¶")
        
        return merged_works
    
    def save_merged_data(self, merged_works: List[Dict]):
        """çµ±åˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ
            if os.path.exists(self.existing_data_path):
                backup_path = f"{self.existing_data_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                import shutil
                shutil.copy2(self.existing_data_path, backup_path)
                print(f"ğŸ“‹ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
            
            # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            with open(self.output_path, 'w', encoding='utf-8') as f:
                json.dump(merged_works, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {self.output_path}")
            
            # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
            self.display_statistics(merged_works)
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def display_statistics(self, works: List[Dict]):
        """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
        print(f"\nğŸ“Š çµ±åˆå¾Œã®çµ±è¨ˆæƒ…å ±")
        print(f"{'='*50}")
        
        # å¥³å„ªåˆ¥ã®ä½œå“æ•°
        actress_count = {}
        source_count = {'dmm_api': 0, 'existing': 0}
        
        for work in works:
            actress = work.get('actress', 'ä¸æ˜')
            actress_count[actress] = actress_count.get(actress, 0) + 1
            
            source = work.get('source', 'existing')
            source_count[source] = source_count.get(source, 0) + 1
        
        print(f"ğŸ“ˆ ç·ä½œå“æ•°: {len(works)}ä»¶")
        print(f"ğŸ‘¥ å¥³å„ªæ•°: {len(actress_count)}äºº")
        print(f"ğŸ†• DMM APIå–å¾—: {source_count.get('dmm_api', 0)}ä»¶")
        print(f"ğŸ“š æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {source_count.get('existing', 0)}ä»¶")
        
        # ä¸Šä½å¥³å„ª
        print(f"\nğŸ‘‘ ä½œå“æ•°ä¸Šä½å¥³å„ª (TOP 10):")
        sorted_actresses = sorted(actress_count.items(), key=lambda x: x[1], reverse=True)
        for i, (actress, count) in enumerate(sorted_actresses[:10], 1):
            print(f"   {i:2d}. {actress}: {count}ä½œå“")
    
    def integrate(self):
        """ãƒ‡ãƒ¼ã‚¿çµ±åˆã®å®Ÿè¡Œ"""
        print("ğŸ”„ DMM ãƒ‡ãƒ¼ã‚¿çµ±åˆé–‹å§‹")
        print("=" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        existing_works = self.load_existing_data()
        dmm_videos = self.load_dmm_data()
        
        if not dmm_videos:
            print("âš ï¸  çµ±åˆã™ã‚‹DMMãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # DMM ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
        new_works = self.convert_dmm_to_works_format(dmm_videos)
        
        # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸
        merged_works = self.merge_data(existing_works, new_works)
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        self.save_merged_data(merged_works)
        
        print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†!")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”— DMM API ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    try:
        integrator = DMMDataIntegrator()
        integrator.integrate()
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
